{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV6jkDdg-MKy",
        "outputId": "d9bfa080-51ed-4816-e975-249d6c1d2219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git@248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Cloning https://github.com/openai/whisper.git (to revision 248b6cb124225dd263bb9bd32d060b6517e067f8) to /tmp/pip-req-build-bb5rj7xf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-bb5rj7xf\n",
            "  Running command git rev-parse -q --verify 'sha^248b6cb124225dd263bb9bd32d060b6517e067f8'\n",
            "  Running command git fetch -q https://github.com/openai/whisper.git 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Running command git checkout -q 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Resolved https://github.com/openai/whisper.git to commit 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton==2.0.0 (from openai-whisper==20230314)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20230314) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20230314) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20230314) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20230314) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20230314) (10.5.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230314)\n",
            "  Downloading tiktoken-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.32.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.31.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.17.0)\n",
            "Collecting lit (from triton==2.0.0->openai-whisper==20230314)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20230314) (0.43.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20230314) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20230314) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20230314) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20230314) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20230314) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20230314) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper==20230314)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting torch (from openai-whisper==20230314)\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "  Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20230314) (1.13.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting torch (from openai-whisper==20230314)\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "  Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting torch (from openai-whisper==20230314)\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "INFO: pip is still looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting torch (from openai-whisper==20230314)\n",
            "  Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "  Downloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting torch (from openai-whisper==20230314)\n",
            "  Downloading torch-2.1.1-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20230314)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230314) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230314) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20230314) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Downloading tiktoken-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798125 sha256=5e4181ced6039d203bb590b905877f8283a8c11f019a15a81adb83bd58bcd2dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ac/89/47a6f851819664ad059984f44d7b6ea51b28b9760fddedb9b1\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20230314 tiktoken-0.3.3 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git@248b6cb124225dd263bb9bd32d060b6517e067f8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nPQKpbg_JOi",
        "outputId": "340d2e54-688d-4f2a-a20f-d5daacbae7a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jaimin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': \" Imagine a world where iModels can be trained on data from millions of devices without. Compromising user privacy. That's the power of federated learning. This game changing approach allows us to train models locally on each device and share only K. Updates. Protecting sensitive user data and reducing communication costs. Not only does federated learning. Prioritize user privacy, but it also leads to faster training times and improved model performance. It's a win-win-win for users, developers and the environment. Our algorithms like FedAVG and FedSGD. Combine models from multiple clients to achieve better performance. With impressive results, FedAVG has outperformed FedSGD in many cases. Achieving higher accuracy and faster convergence. As we move forward, we are working to develop stronger privacy guarantees and improve scalability and efficiency for. Large-scale applications. The potential of federated learning is vast. With the power to transform industries like healthcare, finance and education. This decentralized, private and efficient approach to machine learning has the potential to revolutionize the way we live in. Work. Let's harness its potential and create a future where AI benefits everyone while protecting. Individual privacy and security.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 5.6, 'text': ' Imagine a world where iModels can be trained on data from millions of devices without.', 'tokens': [50364, 11739, 257, 1002, 689, 741, 44, 378, 1625, 393, 312, 8895, 322, 1412, 490, 6803, 295, 5759, 1553, 13, 50644], 'temperature': 0.0, 'avg_logprob': -0.15641266622661074, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.007222069893032312, 'words': [{'word': ' Imagine', 'start': 0.0, 'end': 0.36, 'probability': 0.8564739227294922}, {'word': ' a', 'start': 0.36, 'end': 0.76, 'probability': 0.9977407455444336}, {'word': ' world', 'start': 0.76, 'end': 1.04, 'probability': 0.9818443655967712}, {'word': ' where', 'start': 1.04, 'end': 1.38, 'probability': 0.9969279170036316}, {'word': ' iModels', 'start': 1.38, 'end': 2.16, 'probability': 0.7262221276760101}, {'word': ' can', 'start': 2.16, 'end': 2.38, 'probability': 0.9926283359527588}, {'word': ' be', 'start': 2.38, 'end': 2.58, 'probability': 0.9986492991447449}, {'word': ' trained', 'start': 2.58, 'end': 2.88, 'probability': 0.982254683971405}, {'word': ' on', 'start': 2.88, 'end': 3.14, 'probability': 0.9982220530509949}, {'word': ' data', 'start': 3.14, 'end': 3.48, 'probability': 0.9699801802635193}, {'word': ' from', 'start': 3.48, 'end': 3.78, 'probability': 0.9956134557723999}, {'word': ' millions', 'start': 3.78, 'end': 4.14, 'probability': 0.9915265440940857}, {'word': ' of', 'start': 4.14, 'end': 4.46, 'probability': 0.9976494908332825}, {'word': ' devices', 'start': 4.46, 'end': 4.92, 'probability': 0.994070827960968}, {'word': ' without.', 'start': 4.92, 'end': 5.6, 'probability': 0.9920206665992737}]}, {'id': 1, 'seek': 0, 'start': 6.480000000000002, 'end': 13.08, 'text': \" Compromising user privacy. That's the power of federated learning. This game changing approach\", 'tokens': [50684, 2432, 28722, 3436, 4195, 11427, 13, 663, 311, 264, 1347, 295, 38024, 770, 2539, 13, 639, 1216, 4473, 3109, 51024], 'temperature': 0.0, 'avg_logprob': -0.15641266622661074, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.007222069893032312, 'words': [{'word': ' Compromising', 'start': 6.480000000000002, 'end': 7.26, 'probability': 0.9548748731613159}, {'word': ' user', 'start': 7.26, 'end': 7.72, 'probability': 0.8316062092781067}, {'word': ' privacy.', 'start': 7.72, 'end': 8.24, 'probability': 0.9565376043319702}, {'word': \" That's\", 'start': 8.72, 'end': 9.12, 'probability': 0.9669206142425537}, {'word': ' the', 'start': 9.12, 'end': 9.26, 'probability': 0.9943166375160217}, {'word': ' power', 'start': 9.26, 'end': 9.56, 'probability': 0.9656765460968018}, {'word': ' of', 'start': 9.56, 'end': 9.84, 'probability': 0.9982498288154602}, {'word': ' federated', 'start': 9.84, 'end': 10.46, 'probability': 0.8740350306034088}, {'word': ' learning.', 'start': 10.46, 'end': 10.92, 'probability': 0.9979156851768494}, {'word': ' This', 'start': 11.48, 'end': 11.82, 'probability': 0.9915363788604736}, {'word': ' game', 'start': 11.82, 'end': 12.06, 'probability': 0.9213030338287354}, {'word': ' changing', 'start': 12.06, 'end': 12.58, 'probability': 0.3163234293460846}, {'word': ' approach', 'start': 12.58, 'end': 13.08, 'probability': 0.9983993172645569}]}, {'id': 2, 'seek': 0, 'start': 13.08, 'end': 17.62, 'text': ' allows us to train models locally on each device and share only K.', 'tokens': [51024, 4045, 505, 281, 3847, 5245, 16143, 322, 1184, 4302, 293, 2073, 787, 591, 13, 51244], 'temperature': 0.0, 'avg_logprob': -0.15641266622661074, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.007222069893032312, 'words': [{'word': ' allows', 'start': 13.08, 'end': 13.52, 'probability': 0.9954397678375244}, {'word': ' us', 'start': 13.52, 'end': 13.8, 'probability': 0.9988258481025696}, {'word': ' to', 'start': 13.8, 'end': 14.0, 'probability': 0.9976048469543457}, {'word': ' train', 'start': 14.0, 'end': 14.3, 'probability': 0.9901817440986633}, {'word': ' models', 'start': 14.3, 'end': 14.74, 'probability': 0.9671131372451782}, {'word': ' locally', 'start': 14.74, 'end': 15.32, 'probability': 0.9978970289230347}, {'word': ' on', 'start': 15.32, 'end': 15.64, 'probability': 0.9988160133361816}, {'word': ' each', 'start': 15.64, 'end': 15.92, 'probability': 0.9992448091506958}, {'word': ' device', 'start': 15.92, 'end': 16.32, 'probability': 0.9943870306015015}, {'word': ' and', 'start': 16.32, 'end': 16.66, 'probability': 0.9841327667236328}, {'word': ' share', 'start': 16.66, 'end': 16.92, 'probability': 0.9966321587562561}, {'word': ' only', 'start': 16.92, 'end': 17.28, 'probability': 0.9610893726348877}, {'word': ' K.', 'start': 17.28, 'end': 17.62, 'probability': 0.18806038796901703}]}, {'id': 3, 'seek': 0, 'start': 18.38, 'end': 25.92, 'text': ' Updates. Protecting sensitive user data and reducing communication costs. Not only does federated', 'tokens': [51284, 5858, 67, 1024, 13, 32017, 278, 9477, 4195, 1412, 293, 12245, 6101, 5497, 13, 1726, 787, 775, 38024, 770, 51660], 'temperature': 0.0, 'avg_logprob': -0.15641266622661074, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.007222069893032312, 'words': [{'word': ' Updates.', 'start': 18.38, 'end': 19.16, 'probability': 0.9464568297068278}, {'word': ' Protecting', 'start': 19.64, 'end': 20.28, 'probability': 0.9713290929794312}, {'word': ' sensitive', 'start': 20.28, 'end': 20.8, 'probability': 0.9878425598144531}, {'word': ' user', 'start': 20.8, 'end': 21.26, 'probability': 0.9943827390670776}, {'word': ' data', 'start': 21.26, 'end': 21.72, 'probability': 0.9980265498161316}, {'word': ' and', 'start': 21.72, 'end': 21.96, 'probability': 0.9818098545074463}, {'word': ' reducing', 'start': 21.96, 'end': 22.32, 'probability': 0.9943386912345886}, {'word': ' communication', 'start': 22.32, 'end': 23.12, 'probability': 0.9944427609443665}, {'word': ' costs.', 'start': 23.12, 'end': 23.94, 'probability': 0.9961709380149841}, {'word': ' Not', 'start': 24.46, 'end': 24.64, 'probability': 0.9884340167045593}, {'word': ' only', 'start': 24.64, 'end': 25.02, 'probability': 0.9948241710662842}, {'word': ' does', 'start': 25.02, 'end': 25.26, 'probability': 0.9962691068649292}, {'word': ' federated', 'start': 25.26, 'end': 25.92, 'probability': 0.9669573605060577}]}, {'id': 4, 'seek': 2592, 'start': 25.92, 'end': 32.96, 'text': ' learning. Prioritize user privacy, but it also leads to faster training times and improved', 'tokens': [50364, 2539, 13, 24032, 270, 1125, 4195, 11427, 11, 457, 309, 611, 6689, 281, 4663, 3097, 1413, 293, 9689, 50716], 'temperature': 0.0, 'avg_logprob': -0.1538288144097812, 'compression_ratio': 1.4329896907216495, 'no_speech_prob': 0.040217410773038864, 'words': [{'word': ' learning.', 'start': 25.92, 'end': 26.42, 'probability': 0.37463051080703735}, {'word': ' Prioritize', 'start': 27.44, 'end': 28.28, 'probability': 0.9464312593142191}, {'word': ' user', 'start': 28.28, 'end': 28.64, 'probability': 0.9699205160140991}, {'word': ' privacy,', 'start': 28.64, 'end': 29.16, 'probability': 0.9824835658073425}, {'word': ' but', 'start': 29.58, 'end': 29.8, 'probability': 0.9961745738983154}, {'word': ' it', 'start': 29.8, 'end': 29.96, 'probability': 0.9863641858100891}, {'word': ' also', 'start': 29.96, 'end': 30.38, 'probability': 0.996452808380127}, {'word': ' leads', 'start': 30.38, 'end': 30.62, 'probability': 0.9953628778457642}, {'word': ' to', 'start': 30.62, 'end': 30.94, 'probability': 0.9991045594215393}, {'word': ' faster', 'start': 30.94, 'end': 31.22, 'probability': 0.9900173544883728}, {'word': ' training', 'start': 31.22, 'end': 31.8, 'probability': 0.9891663193702698}, {'word': ' times', 'start': 31.8, 'end': 32.3, 'probability': 0.9915897250175476}, {'word': ' and', 'start': 32.3, 'end': 32.48, 'probability': 0.8729579448699951}, {'word': ' improved', 'start': 32.48, 'end': 32.96, 'probability': 0.9963284134864807}]}, {'id': 5, 'seek': 2592, 'start': 32.96, 'end': 41.4, 'text': \" model performance. It's a win-win-win for users, developers and the environment. Our algorithms\", 'tokens': [50716, 2316, 3389, 13, 467, 311, 257, 1942, 12, 9136, 12, 9136, 337, 5022, 11, 8849, 293, 264, 2823, 13, 2621, 14642, 51168], 'temperature': 0.0, 'avg_logprob': -0.1538288144097812, 'compression_ratio': 1.4329896907216495, 'no_speech_prob': 0.040217410773038864, 'words': [{'word': ' model', 'start': 32.96, 'end': 33.38, 'probability': 0.98272705078125}, {'word': ' performance.', 'start': 33.38, 'end': 33.98, 'probability': 0.9913451671600342}, {'word': \" It's\", 'start': 34.98, 'end': 35.4, 'probability': 0.9223214685916901}, {'word': ' a', 'start': 35.4, 'end': 35.5, 'probability': 0.984503984451294}, {'word': ' win', 'start': 35.5, 'end': 35.74, 'probability': 0.9825825691223145}, {'word': '-win', 'start': 35.74, 'end': 36.0, 'probability': 0.8533278405666351}, {'word': '-win', 'start': 36.0, 'end': 36.26, 'probability': 0.841867595911026}, {'word': ' for', 'start': 36.26, 'end': 36.5, 'probability': 0.996896505355835}, {'word': ' users,', 'start': 36.5, 'end': 36.88, 'probability': 0.9925739765167236}, {'word': ' developers', 'start': 37.74, 'end': 38.3, 'probability': 0.9838539958000183}, {'word': ' and', 'start': 38.3, 'end': 39.16, 'probability': 0.4603751003742218}, {'word': ' the', 'start': 39.16, 'end': 39.4, 'probability': 0.9930739402770996}, {'word': ' environment.', 'start': 39.4, 'end': 40.06, 'probability': 0.9901307821273804}, {'word': ' Our', 'start': 40.58, 'end': 40.78, 'probability': 0.772345244884491}, {'word': ' algorithms', 'start': 40.78, 'end': 41.4, 'probability': 0.9792616367340088}]}, {'id': 6, 'seek': 2592, 'start': 42.0, 'end': 49.18, 'text': ' like FedAVG and FedSGD. Combine models from multiple clients to achieve better performance.', 'tokens': [51168, 411, 7772, 32, 53, 38, 293, 7772, 50, 38, 35, 13, 25939, 533, 5245, 490, 3866, 6982, 281, 4584, 1101, 3389, 13, 51560], 'temperature': 0.0, 'avg_logprob': -0.1538288144097812, 'compression_ratio': 1.4329896907216495, 'no_speech_prob': 0.040217410773038864, 'words': [{'word': ' like', 'start': 41.86, 'end': 42.28, 'probability': 0.24418149888515472}, {'word': ' FedAVG', 'start': 42.28, 'end': 43.38, 'probability': 0.7840273901820183}, {'word': ' and', 'start': 43.38, 'end': 43.64, 'probability': 0.9476302862167358}, {'word': ' FedSGD.', 'start': 43.64, 'end': 44.68, 'probability': 0.9320898205041885}, {'word': ' Combine', 'start': 45.28, 'end': 45.7, 'probability': 0.7762007713317871}, {'word': ' models', 'start': 45.7, 'end': 46.16, 'probability': 0.9946112632751465}, {'word': ' from', 'start': 46.16, 'end': 46.48, 'probability': 0.9963059425354004}, {'word': ' multiple', 'start': 46.48, 'end': 46.96, 'probability': 0.9990794658660889}, {'word': ' clients', 'start': 46.96, 'end': 47.5, 'probability': 0.9893006682395935}, {'word': ' to', 'start': 47.5, 'end': 47.82, 'probability': 0.9988386034965515}, {'word': ' achieve', 'start': 47.82, 'end': 48.18, 'probability': 0.9958179593086243}, {'word': ' better', 'start': 48.18, 'end': 48.58, 'probability': 0.9983221888542175}, {'word': ' performance.', 'start': 48.58, 'end': 49.18, 'probability': 0.9945690631866455}]}, {'id': 7, 'seek': 4918, 'start': 49.82, 'end': 56.04, 'text': ' With impressive results, FedAVG has outperformed FedSGD in many cases.', 'tokens': [50396, 2022, 8992, 3542, 11, 7772, 32, 53, 38, 575, 484, 610, 22892, 7772, 50, 38, 35, 294, 867, 3331, 13, 50704], 'temperature': 0.0, 'avg_logprob': -0.1024169066013434, 'compression_ratio': 1.4588744588744589, 'no_speech_prob': 0.01968109980225563, 'words': [{'word': ' With', 'start': 49.620000000000005, 'end': 50.1, 'probability': 0.1417936384677887}, {'word': ' impressive', 'start': 50.1, 'end': 50.78, 'probability': 0.6997989416122437}, {'word': ' results,', 'start': 50.78, 'end': 51.54, 'probability': 0.9960002303123474}, {'word': ' FedAVG', 'start': 52.0, 'end': 52.82, 'probability': 0.7796376273036003}, {'word': ' has', 'start': 52.82, 'end': 53.14, 'probability': 0.9967660903930664}, {'word': ' outperformed', 'start': 53.14, 'end': 53.96, 'probability': 0.9534235000610352}, {'word': ' FedSGD', 'start': 53.96, 'end': 54.96, 'probability': 0.8063613697886467}, {'word': ' in', 'start': 54.96, 'end': 55.22, 'probability': 0.9877741932868958}, {'word': ' many', 'start': 55.22, 'end': 55.5, 'probability': 0.9991692304611206}, {'word': ' cases.', 'start': 55.5, 'end': 56.04, 'probability': 0.9970011115074158}]}, {'id': 8, 'seek': 4918, 'start': 56.92, 'end': 61.92, 'text': ' Achieving higher accuracy and faster convergence. As we move forward,', 'tokens': [50752, 15847, 30244, 2946, 14170, 293, 4663, 32181, 13, 1018, 321, 1286, 2128, 11, 51020], 'temperature': 0.0, 'avg_logprob': -0.1024169066013434, 'compression_ratio': 1.4588744588744589, 'no_speech_prob': 0.01968109980225563, 'words': [{'word': ' Achieving', 'start': 56.92, 'end': 57.48, 'probability': 0.9580274820327759}, {'word': ' higher', 'start': 57.48, 'end': 57.96, 'probability': 0.9931069016456604}, {'word': ' accuracy', 'start': 57.96, 'end': 58.52, 'probability': 0.9860038161277771}, {'word': ' and', 'start': 58.52, 'end': 58.92, 'probability': 0.9904782772064209}, {'word': ' faster', 'start': 58.92, 'end': 59.4, 'probability': 0.9852452874183655}, {'word': ' convergence.', 'start': 59.4, 'end': 60.04, 'probability': 0.8706985116004944}, {'word': ' As', 'start': 60.68, 'end': 60.88, 'probability': 0.958427369594574}, {'word': ' we', 'start': 60.88, 'end': 61.04, 'probability': 0.9985968470573425}, {'word': ' move', 'start': 61.04, 'end': 61.32, 'probability': 0.9978995323181152}, {'word': ' forward,', 'start': 61.32, 'end': 61.92, 'probability': 0.9959679841995239}]}, {'id': 9, 'seek': 4918, 'start': 62.46, 'end': 68.26, 'text': ' we are working to develop stronger privacy guarantees and improve scalability and efficiency for.', 'tokens': [51020, 321, 366, 1364, 281, 1499, 7249, 11427, 32567, 293, 3470, 15664, 2310, 293, 10493, 337, 13, 51316], 'temperature': 0.0, 'avg_logprob': -0.1024169066013434, 'compression_ratio': 1.4588744588744589, 'no_speech_prob': 0.01968109980225563, 'words': [{'word': ' we', 'start': 62.46, 'end': 62.6, 'probability': 0.9474059343338013}, {'word': ' are', 'start': 62.6, 'end': 62.68, 'probability': 0.8689824938774109}, {'word': ' working', 'start': 62.68, 'end': 63.04, 'probability': 0.9977774024009705}, {'word': ' to', 'start': 63.04, 'end': 63.26, 'probability': 0.9986982345581055}, {'word': ' develop', 'start': 63.26, 'end': 63.58, 'probability': 0.99714595079422}, {'word': ' stronger', 'start': 63.58, 'end': 64.06, 'probability': 0.9881425499916077}, {'word': ' privacy', 'start': 64.06, 'end': 64.76, 'probability': 0.9768837094306946}, {'word': ' guarantees', 'start': 64.76, 'end': 65.38, 'probability': 0.9888932108879089}, {'word': ' and', 'start': 65.38, 'end': 65.72, 'probability': 0.9909528493881226}, {'word': ' improve', 'start': 65.72, 'end': 66.14, 'probability': 0.8269105553627014}, {'word': ' scalability', 'start': 66.14, 'end': 67.02, 'probability': 0.9755183160305023}, {'word': ' and', 'start': 67.02, 'end': 67.28, 'probability': 0.9638720154762268}, {'word': ' efficiency', 'start': 67.28, 'end': 67.74, 'probability': 0.9975864887237549}, {'word': ' for.', 'start': 67.74, 'end': 68.26, 'probability': 0.9678233861923218}]}, {'id': 10, 'seek': 4918, 'start': 69.14, 'end': 76.28, 'text': ' Large-scale applications. The potential of federated learning is vast. With the power to transform', 'tokens': [51360, 33092, 12, 20033, 5821, 13, 440, 3995, 295, 38024, 770, 2539, 307, 8369, 13, 2022, 264, 1347, 281, 4088, 51724], 'temperature': 0.0, 'avg_logprob': -0.1024169066013434, 'compression_ratio': 1.4588744588744589, 'no_speech_prob': 0.01968109980225563, 'words': [{'word': ' Large', 'start': 69.14, 'end': 69.52, 'probability': 0.9647063612937927}, {'word': '-scale', 'start': 69.52, 'end': 69.88, 'probability': 0.867739737033844}, {'word': ' applications.', 'start': 69.88, 'end': 70.68, 'probability': 0.9888476133346558}, {'word': ' The', 'start': 71.3, 'end': 71.48, 'probability': 0.9828422665596008}, {'word': ' potential', 'start': 71.48, 'end': 72.04, 'probability': 0.9892409443855286}, {'word': ' of', 'start': 72.04, 'end': 72.34, 'probability': 0.9950855374336243}, {'word': ' federated', 'start': 72.34, 'end': 72.98, 'probability': 0.8785989582538605}, {'word': ' learning', 'start': 72.98, 'end': 73.42, 'probability': 0.9988762736320496}, {'word': ' is', 'start': 73.42, 'end': 73.74, 'probability': 0.9983285069465637}, {'word': ' vast.', 'start': 73.74, 'end': 74.26, 'probability': 0.9338845610618591}, {'word': ' With', 'start': 74.74, 'end': 74.96, 'probability': 0.968936026096344}, {'word': ' the', 'start': 74.96, 'end': 75.14, 'probability': 0.9976412057876587}, {'word': ' power', 'start': 75.14, 'end': 75.46, 'probability': 0.9966817498207092}, {'word': ' to', 'start': 75.46, 'end': 75.68, 'probability': 0.9974361062049866}, {'word': ' transform', 'start': 75.68, 'end': 76.28, 'probability': 0.9953946471214294}]}, {'id': 11, 'seek': 7628, 'start': 76.28, 'end': 84.8, 'text': ' industries like healthcare, finance and education. This decentralized, private and efficient', 'tokens': [50364, 13284, 411, 8884, 11, 10719, 293, 3309, 13, 639, 32870, 11, 4551, 293, 7148, 50792], 'temperature': 0.0, 'avg_logprob': -0.18253792485883158, 'compression_ratio': 1.4951456310679612, 'no_speech_prob': 0.0037210688460618258, 'words': [{'word': ' industries', 'start': 76.28, 'end': 76.96, 'probability': 0.4985422194004059}, {'word': ' like', 'start': 76.96, 'end': 77.34, 'probability': 0.9764680862426758}, {'word': ' healthcare,', 'start': 77.34, 'end': 77.86, 'probability': 0.7364673018455505}, {'word': ' finance', 'start': 78.56, 'end': 78.98, 'probability': 0.9952835440635681}, {'word': ' and', 'start': 78.98, 'end': 79.88, 'probability': 0.5826930999755859}, {'word': ' education.', 'start': 79.88, 'end': 80.64, 'probability': 0.9969038367271423}, {'word': ' This', 'start': 81.14, 'end': 81.5, 'probability': 0.978108286857605}, {'word': ' decentralized,', 'start': 81.5, 'end': 82.34, 'probability': 0.7009910345077515}, {'word': ' private', 'start': 83.14, 'end': 83.56, 'probability': 0.9883962869644165}, {'word': ' and', 'start': 83.56, 'end': 84.28, 'probability': 0.8873003125190735}, {'word': ' efficient', 'start': 84.28, 'end': 84.8, 'probability': 0.9962091445922852}]}, {'id': 12, 'seek': 7628, 'start': 84.8, 'end': 89.74, 'text': ' approach to machine learning has the potential to revolutionize the way we live in.', 'tokens': [50792, 3109, 281, 3479, 2539, 575, 264, 3995, 281, 8894, 1125, 264, 636, 321, 1621, 294, 13, 51032], 'temperature': 0.0, 'avg_logprob': -0.18253792485883158, 'compression_ratio': 1.4951456310679612, 'no_speech_prob': 0.0037210688460618258, 'words': [{'word': ' approach', 'start': 84.8, 'end': 85.32, 'probability': 0.9991711378097534}, {'word': ' to', 'start': 85.32, 'end': 85.6, 'probability': 0.9979085922241211}, {'word': ' machine', 'start': 85.6, 'end': 85.92, 'probability': 0.9743625521659851}, {'word': ' learning', 'start': 85.92, 'end': 86.4, 'probability': 0.9448255300521851}, {'word': ' has', 'start': 86.4, 'end': 86.7, 'probability': 0.9948166012763977}, {'word': ' the', 'start': 86.7, 'end': 86.84, 'probability': 0.9982950091362}, {'word': ' potential', 'start': 86.84, 'end': 87.3, 'probability': 0.9995517134666443}, {'word': ' to', 'start': 87.3, 'end': 87.66, 'probability': 0.9994660019874573}, {'word': ' revolutionize', 'start': 87.66, 'end': 88.54, 'probability': 0.9462582767009735}, {'word': ' the', 'start': 88.54, 'end': 88.76, 'probability': 0.998572587966919}, {'word': ' way', 'start': 88.76, 'end': 88.98, 'probability': 0.9850239753723145}, {'word': ' we', 'start': 88.98, 'end': 89.16, 'probability': 0.998710036277771}, {'word': ' live', 'start': 89.16, 'end': 89.5, 'probability': 0.9993558526039124}, {'word': ' in.', 'start': 89.5, 'end': 89.74, 'probability': 0.9426982402801514}]}, {'id': 13, 'seek': 7628, 'start': 90.56, 'end': 96.94, 'text': \" Work. Let's harness its potential and create a future where AI benefits everyone while protecting.\", 'tokens': [51076, 6603, 13, 961, 311, 19700, 1080, 3995, 293, 1884, 257, 2027, 689, 7318, 5311, 1518, 1339, 12316, 13, 51400], 'temperature': 0.0, 'avg_logprob': -0.18253792485883158, 'compression_ratio': 1.4951456310679612, 'no_speech_prob': 0.0037210688460618258, 'words': [{'word': ' Work.', 'start': 90.56, 'end': 90.94, 'probability': 0.8791314363479614}, {'word': \" Let's\", 'start': 91.42, 'end': 91.82, 'probability': 0.874051958322525}, {'word': ' harness', 'start': 91.82, 'end': 92.06, 'probability': 0.9968069791793823}, {'word': ' its', 'start': 92.06, 'end': 92.36, 'probability': 0.9696192741394043}, {'word': ' potential', 'start': 92.36, 'end': 93.0, 'probability': 0.999508261680603}, {'word': ' and', 'start': 93.0, 'end': 93.22, 'probability': 0.8018187880516052}, {'word': ' create', 'start': 93.22, 'end': 93.54, 'probability': 0.9984323382377625}, {'word': ' a', 'start': 93.54, 'end': 93.78, 'probability': 0.9995515942573547}, {'word': ' future', 'start': 93.78, 'end': 94.2, 'probability': 0.9971683621406555}, {'word': ' where', 'start': 94.2, 'end': 94.54, 'probability': 0.9873979091644287}, {'word': ' AI', 'start': 94.54, 'end': 94.88, 'probability': 0.5946520566940308}, {'word': ' benefits', 'start': 94.88, 'end': 95.34, 'probability': 0.9945372939109802}, {'word': ' everyone', 'start': 95.34, 'end': 96.0, 'probability': 0.9803577065467834}, {'word': ' while', 'start': 96.0, 'end': 96.34, 'probability': 0.9923215508460999}, {'word': ' protecting.', 'start': 96.34, 'end': 96.94, 'probability': 0.9965177774429321}]}, {'id': 14, 'seek': 7628, 'start': 97.98, 'end': 100.1, 'text': ' Individual privacy and security.', 'tokens': [51444, 37292, 11427, 293, 3825, 13, 51856], 'temperature': 0.0, 'avg_logprob': -0.18253792485883158, 'compression_ratio': 1.4951456310679612, 'no_speech_prob': 0.0037210688460618258, 'words': [{'word': ' Individual', 'start': 97.98, 'end': 98.46, 'probability': 0.9687512516975403}, {'word': ' privacy', 'start': 98.46, 'end': 99.2, 'probability': 0.7401283383369446}, {'word': ' and', 'start': 99.2, 'end': 99.44, 'probability': 0.9865273833274841}, {'word': ' security.', 'start': 99.44, 'end': 100.1, 'probability': 0.9917923212051392}]}], 'language': 'en'}\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "                                          #might take some time (approx 3- 5min depending on audio length)\n",
        "model = whisper.load_model(\"base\")\n",
        "audiofilename=\"./uploads/audio.mp3\"\n",
        "result = model.transcribe(audiofilename,word_timestamps=True)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vms-fInF_JgW",
        "outputId": "f95da903-3170-4c4b-f545-2fe24231b4e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Imagine a world where iModels can be trained on data from millions of devices without. Compromising user privacy. That's the power of federated learning. This game changing approach allows us to train models locally on each device and share only K. Updates. Protecting sensitive user data and reducing communication costs. Not only does federated learning. Prioritize user privacy, but it also leads to faster training times and improved model performance. It's a win-win-win for users, developers and the environment. Our algorithms like FedAVG and FedSGD. Combine models from multiple clients to achieve better performance. With impressive results, FedAVG has outperformed FedSGD in many cases. Achieving higher accuracy and faster convergence. As we move forward, we are working to develop stronger privacy guarantees and improve scalability and efficiency for. Large-scale applications. The potential of federated learning is vast. With the power to transform industries like healthcare, finance and education. This decentralized, private and efficient approach to machine learning has the potential to revolutionize the way we live in. Work. Let's harness its potential and create a future where AI benefits everyone while protecting. Individual privacy and security.\n"
          ]
        }
      ],
      "source": [
        "# total text\n",
        "print (result['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT-GTWxU_Jtt",
        "outputId": "637e39bf-86bf-4f9c-ddc4-02a3f3962a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 0, 'seek': 0, 'start': 0.0, 'end': 5.24, 'text': ' Key insights from the paper, Comprehensive Health Data Analysis for Early', 'tokens': [50364, 12759, 14310, 490, 264, 3035, 11, 2432, 40128, 2953, 5912, 11888, 38172, 337, 18344, 50654], 'temperature': 0.0, 'avg_logprob': -0.39575232080666417, 'compression_ratio': 1.6611111111111112, 'no_speech_prob': 0.04942928999662399, 'words': [{'word': ' Key', 'start': 0.0, 'end': 0.26, 'probability': 0.6267980933189392}, {'word': ' insights', 'start': 0.26, 'end': 0.74, 'probability': 0.6912855505943298}, {'word': ' from', 'start': 0.74, 'end': 1.14, 'probability': 0.9954357743263245}, {'word': ' the', 'start': 1.14, 'end': 1.34, 'probability': 0.9780535697937012}, {'word': ' paper,', 'start': 1.34, 'end': 1.7, 'probability': 0.9896302819252014}, {'word': ' Comprehensive', 'start': 2.34, 'end': 3.14, 'probability': 0.9515424172083536}, {'word': ' Health', 'start': 3.14, 'end': 3.42, 'probability': 0.9395983219146729}, {'word': ' Data', 'start': 3.42, 'end': 3.92, 'probability': 0.9479236602783203}, {'word': ' Analysis', 'start': 3.92, 'end': 4.42, 'probability': 0.9842256307601929}, {'word': ' for', 'start': 4.42, 'end': 4.84, 'probability': 0.8992811441421509}, {'word': ' Early', 'start': 4.84, 'end': 5.24, 'probability': 0.8878518342971802}]}\n",
            "{'id': 1, 'seek': 0, 'start': 5.24, 'end': 9.36, 'text': ' Dementure Diagnosis, a Machine Learning approach.', 'tokens': [50654, 413, 1712, 540, 8789, 4535, 8211, 11, 257, 22155, 15205, 3109, 13, 50853], 'temperature': 0.0, 'avg_logprob': -0.39575232080666417, 'compression_ratio': 1.6611111111111112, 'no_speech_prob': 0.04942928999662399, 'words': [{'word': ' Dementure', 'start': 5.24, 'end': 6.5, 'probability': 0.5919267386198044}, {'word': ' Diagnosis,', 'start': 6.5, 'end': 7.22, 'probability': 0.9303088585535685}, {'word': ' a', 'start': 7.74, 'end': 7.88, 'probability': 0.6965426206588745}, {'word': ' Machine', 'start': 7.88, 'end': 8.22, 'probability': 0.7024518251419067}, {'word': ' Learning', 'start': 8.22, 'end': 8.68, 'probability': 0.9537452459335327}, {'word': ' approach.', 'start': 8.68, 'end': 9.36, 'probability': 0.560514509677887}]}\n",
            "{'id': 2, 'seek': 0, 'start': 9.92, 'end': 13.28, 'text': ' J. Min Salvi, Asterisk Operator, Agam Shah,', 'tokens': [50853, 508, 13, 2829, 5996, 4917, 11, 316, 3120, 7797, 12480, 1639, 11, 2725, 335, 21159, 11, 51057], 'temperature': 0.0, 'avg_logprob': -0.39575232080666417, 'compression_ratio': 1.6611111111111112, 'no_speech_prob': 0.04942928999662399, 'words': [{'word': ' J.', 'start': 9.92, 'end': 9.98, 'probability': 0.5175275802612305}, {'word': ' Min', 'start': 10.04, 'end': 10.26, 'probability': 0.2758010923862457}, {'word': ' Salvi,', 'start': 10.26, 'end': 10.82, 'probability': 0.6246017217636108}, {'word': ' Asterisk', 'start': 11.0, 'end': 11.54, 'probability': 0.7290743688742319}, {'word': ' Operator,', 'start': 11.54, 'end': 12.2, 'probability': 0.9250982403755188}, {'word': ' Agam', 'start': 12.64, 'end': 13.02, 'probability': 0.696016252040863}, {'word': ' Shah,', 'start': 13.02, 'end': 13.28, 'probability': 0.8120845556259155}]}\n",
            "{'id': 3, 'seek': 0, 'start': 13.86, 'end': 17.1, 'text': ' Asterisk Operator Department of Computer Science,', 'tokens': [51057, 316, 3120, 7797, 12480, 1639, 5982, 295, 22289, 8976, 11, 51252], 'temperature': 0.0, 'avg_logprob': -0.39575232080666417, 'compression_ratio': 1.6611111111111112, 'no_speech_prob': 0.04942928999662399, 'words': [{'word': ' Asterisk', 'start': 13.86, 'end': 14.6, 'probability': 0.9751179615656534}, {'word': ' Operator', 'start': 14.6, 'end': 15.22, 'probability': 0.9902553856372833}, {'word': ' Department', 'start': 15.22, 'end': 15.76, 'probability': 0.6341911554336548}, {'word': ' of', 'start': 15.76, 'end': 16.16, 'probability': 0.9968020915985107}, {'word': ' Computer', 'start': 16.16, 'end': 16.56, 'probability': 0.9843047261238098}, {'word': ' Science,', 'start': 16.56, 'end': 17.1, 'probability': 0.9777891039848328}]}\n",
            "{'id': 4, 'seek': 0, 'start': 17.82, 'end': 25.16, 'text': ' NIRMA University, India, Department of Computer Science, NIRMA University, India,', 'tokens': [51252, 426, 7740, 9998, 3535, 11, 5282, 11, 5982, 295, 22289, 8976, 11, 426, 7740, 9998, 3535, 11, 5282, 11, 51644], 'temperature': 0.0, 'avg_logprob': -0.39575232080666417, 'compression_ratio': 1.6611111111111112, 'no_speech_prob': 0.04942928999662399, 'words': [{'word': ' NIRMA', 'start': 17.82, 'end': 18.2, 'probability': 0.8067743976910909}, {'word': ' University,', 'start': 18.2, 'end': 19.04, 'probability': 0.9595456123352051}, {'word': ' India,', 'start': 19.58, 'end': 20.0, 'probability': 0.9940398931503296}, {'word': ' Department', 'start': 20.36, 'end': 21.0, 'probability': 0.9648022055625916}, {'word': ' of', 'start': 21.0, 'end': 21.4, 'probability': 0.9987497329711914}, {'word': ' Computer', 'start': 21.4, 'end': 21.8, 'probability': 0.9869246482849121}, {'word': ' Science,', 'start': 21.8, 'end': 22.44, 'probability': 0.992401123046875}, {'word': ' NIRMA', 'start': 23.0, 'end': 23.36, 'probability': 0.9845415353775024}, {'word': ' University,', 'start': 23.36, 'end': 24.16, 'probability': 0.9693374037742615}, {'word': ' India,', 'start': 24.76, 'end': 25.16, 'probability': 0.9984114170074463}]}\n",
            "{'id': 5, 'seek': 2516, 'start': 25.66, 'end': 26.5, 'text': ' ABSTRACT.', 'tokens': [50364, 316, 8176, 51, 3750, 10259, 13, 50457], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' ABSTRACT.', 'start': 25.66, 'end': 26.5, 'probability': 0.348193621635437}]}\n",
            "{'id': 6, 'seek': 2516, 'start': 26.74, 'end': 29.92, 'text': ' This paper investigates the application of machine.', 'tokens': [50457, 639, 3035, 4557, 1024, 264, 3861, 295, 3479, 13, 50648], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' This', 'start': 26.74, 'end': 27.1, 'probability': 0.9293639063835144}, {'word': ' paper', 'start': 27.1, 'end': 27.44, 'probability': 0.9949866533279419}, {'word': ' investigates', 'start': 27.44, 'end': 28.46, 'probability': 0.9899157881736755}, {'word': ' the', 'start': 28.46, 'end': 28.64, 'probability': 0.9980872273445129}, {'word': ' application', 'start': 28.64, 'end': 29.28, 'probability': 0.9931815266609192}, {'word': ' of', 'start': 29.28, 'end': 29.54, 'probability': 0.9974595904350281}, {'word': ' machine.', 'start': 29.54, 'end': 29.92, 'probability': 0.8588969111442566}]}\n",
            "{'id': 7, 'seek': 2516, 'start': 30.68, 'end': 31.04, 'text': ' Learning.', 'tokens': [50648, 15205, 13, 50698], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' Learning.', 'start': 30.68, 'end': 31.04, 'probability': 0.9282825589179993}]}\n",
            "{'id': 8, 'seek': 2516, 'start': 31.58, 'end': 32.26, 'text': ' Milliliter.', 'tokens': [50698, 7190, 388, 1681, 13, 50748], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' Milliliter.', 'start': 31.58, 'end': 32.26, 'probability': 0.7260221242904663}]}\n",
            "{'id': 9, 'seek': 2516, 'start': 32.7, 'end': 38.26, 'text': ' Models to predict dementia diagnosis using a Comprehensive Health Data Set.', 'tokens': [50748, 6583, 1625, 281, 6069, 31734, 15217, 1228, 257, 2432, 40128, 2953, 5912, 11888, 8928, 13, 51046], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' Models', 'start': 32.7, 'end': 33.18, 'probability': 0.981797844171524}, {'word': ' to', 'start': 33.18, 'end': 33.36, 'probability': 0.9858766794204712}, {'word': ' predict', 'start': 33.36, 'end': 33.68, 'probability': 0.9621889591217041}, {'word': ' dementia', 'start': 33.68, 'end': 34.4, 'probability': 0.9558001756668091}, {'word': ' diagnosis', 'start': 34.4, 'end': 35.1, 'probability': 0.849221408367157}, {'word': ' using', 'start': 35.1, 'end': 35.74, 'probability': 0.9510469436645508}, {'word': ' a', 'start': 35.74, 'end': 35.96, 'probability': 0.9767225384712219}, {'word': ' Comprehensive', 'start': 35.96, 'end': 37.2, 'probability': 0.8135794599850973}, {'word': ' Health', 'start': 37.2, 'end': 37.5, 'probability': 0.7444384694099426}, {'word': ' Data', 'start': 37.5, 'end': 37.84, 'probability': 0.31123486161231995}, {'word': ' Set.', 'start': 37.84, 'end': 38.26, 'probability': 0.5910477042198181}]}\n",
            "{'id': 10, 'seek': 2516, 'start': 38.56, 'end': 44.74, 'text': ' The data set includes key health-related features such as diabetic status, heart rate,', 'tokens': [51046, 440, 1412, 992, 5974, 2141, 1585, 12, 12004, 4122, 1270, 382, 50238, 6558, 11, 1917, 3314, 11, 51372], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' The', 'start': 38.56, 'end': 38.82, 'probability': 0.9861391186714172}, {'word': ' data', 'start': 38.82, 'end': 39.12, 'probability': 0.8633249402046204}, {'word': ' set', 'start': 39.12, 'end': 39.58, 'probability': 0.9802200198173523}, {'word': ' includes', 'start': 39.58, 'end': 39.94, 'probability': 0.9964978098869324}, {'word': ' key', 'start': 39.94, 'end': 40.36, 'probability': 0.9132821559906006}, {'word': ' health', 'start': 40.36, 'end': 40.72, 'probability': 0.9787580966949463}, {'word': '-related', 'start': 40.72, 'end': 41.06, 'probability': 0.8990236818790436}, {'word': ' features', 'start': 41.06, 'end': 41.6, 'probability': 0.9916526675224304}, {'word': ' such', 'start': 41.6, 'end': 42.04, 'probability': 0.9658575654029846}, {'word': ' as', 'start': 42.04, 'end': 42.26, 'probability': 0.9987834095954895}, {'word': ' diabetic', 'start': 42.26, 'end': 42.7, 'probability': 0.8828626871109009}, {'word': ' status,', 'start': 42.7, 'end': 43.38, 'probability': 0.8808616995811462}, {'word': ' heart', 'start': 44.14, 'end': 44.34, 'probability': 0.9836365580558777}, {'word': ' rate,', 'start': 44.34, 'end': 44.74, 'probability': 0.9693946242332458}]}\n",
            "{'id': 11, 'seek': 2516, 'start': 45.22, 'end': 51.86, 'text': ' blood oxygen, levels, body temperature, cognitive test scores, and lifestyle.', 'tokens': [51372, 3390, 9169, 11, 4358, 11, 1772, 4292, 11, 15605, 1500, 13444, 11, 293, 11716, 13, 51762], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' blood', 'start': 45.22, 'end': 45.48, 'probability': 0.9946626424789429}, {'word': ' oxygen,', 'start': 45.48, 'end': 46.14, 'probability': 0.921692967414856}, {'word': ' levels,', 'start': 46.74, 'end': 47.1, 'probability': 0.9879030585289001}, {'word': ' body', 'start': 47.68, 'end': 48.1, 'probability': 0.9950211048126221}, {'word': ' temperature,', 'start': 48.1, 'end': 48.76, 'probability': 0.998327910900116}, {'word': ' cognitive', 'start': 49.26, 'end': 49.64, 'probability': 0.940680742263794}, {'word': ' test', 'start': 49.64, 'end': 50.26, 'probability': 0.9012503027915955}, {'word': ' scores,', 'start': 50.26, 'end': 50.8, 'probability': 0.9955818057060242}, {'word': ' and', 'start': 51.12, 'end': 51.48, 'probability': 0.9959551095962524}, {'word': ' lifestyle.', 'start': 51.48, 'end': 51.86, 'probability': 0.9728116989135742}]}\n",
            "{'id': 12, 'seek': 2516, 'start': 52.74, 'end': 53.4, 'text': ' Factors.', 'tokens': [51762, 33375, 830, 13, 51812], 'temperature': 0.0, 'avg_logprob': -0.3412164409508866, 'compression_ratio': 1.4353448275862069, 'no_speech_prob': 0.12043920159339905, 'words': [{'word': ' Factors.', 'start': 52.74, 'end': 53.4, 'probability': 0.9514572322368622}]}\n",
            "{'id': 13, 'seek': 5340, 'start': 53.4, 'end': 57.48, 'text': ' We employed milliliter techniques to predict dementia onset.', 'tokens': [50364, 492, 20115, 1728, 388, 1681, 7512, 281, 6069, 31734, 34948, 13, 50610], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' We', 'start': 53.4, 'end': 53.92, 'probability': 0.17359867691993713}, {'word': ' employed', 'start': 53.92, 'end': 54.52, 'probability': 0.5696052312850952}, {'word': ' milliliter', 'start': 54.52, 'end': 55.16, 'probability': 0.8682083090146383}, {'word': ' techniques', 'start': 55.16, 'end': 55.62, 'probability': 0.9797484278678894}, {'word': ' to', 'start': 55.62, 'end': 55.94, 'probability': 0.9982588887214661}, {'word': ' predict', 'start': 55.94, 'end': 56.26, 'probability': 0.9920288920402527}, {'word': ' dementia', 'start': 56.26, 'end': 56.94, 'probability': 0.9373140335083008}, {'word': ' onset.', 'start': 56.94, 'end': 57.48, 'probability': 0.4618186056613922}]}\n",
            "{'id': 14, 'seek': 5340, 'start': 58.24, 'end': 61.58, 'text': ' Leveraging algorithms such as support vector machines.', 'tokens': [50610, 441, 1054, 3568, 14642, 1270, 382, 1406, 8062, 8379, 13, 50796], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' Leveraging', 'start': 58.24, 'end': 58.84, 'probability': 0.7817079325517019}, {'word': ' algorithms', 'start': 58.84, 'end': 59.52, 'probability': 0.8935314416885376}, {'word': ' such', 'start': 59.52, 'end': 59.98, 'probability': 0.9820473194122314}, {'word': ' as', 'start': 59.98, 'end': 60.12, 'probability': 0.9981112480163574}, {'word': ' support', 'start': 60.12, 'end': 60.52, 'probability': 0.9590005278587341}, {'word': ' vector', 'start': 60.52, 'end': 61.0, 'probability': 0.9834733605384827}, {'word': ' machines.', 'start': 61.0, 'end': 61.58, 'probability': 0.997369647026062}]}\n",
            "{'id': 15, 'seek': 5340, 'start': 62.24, 'end': 63.12, 'text': ' SVM.', 'tokens': [50796, 31910, 44, 13, 50880], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' SVM.', 'start': 62.24, 'end': 63.12, 'probability': 0.7169705033302307}]}\n",
            "{'id': 16, 'seek': 5340, 'start': 63.54, 'end': 65.08, 'text': ' And Logistic Regression.', 'tokens': [50880, 400, 10824, 3142, 4791, 2775, 13, 50982], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' And', 'start': 63.54, 'end': 63.74, 'probability': 0.7607117891311646}, {'word': ' Logistic', 'start': 63.74, 'end': 64.34, 'probability': 0.637157753109932}, {'word': ' Regression.', 'start': 64.34, 'end': 65.08, 'probability': 0.7576745450496674}]}\n",
            "{'id': 17, 'seek': 5340, 'start': 65.62, 'end': 68.04, 'text': ' Our findings demonstrate that milliliter.', 'tokens': [50982, 2621, 16483, 11698, 300, 1728, 388, 1681, 13, 51142], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' Our', 'start': 65.62, 'end': 65.76, 'probability': 0.8406217098236084}, {'word': ' findings', 'start': 65.76, 'end': 66.2, 'probability': 0.9915819764137268}, {'word': ' demonstrate', 'start': 66.2, 'end': 67.0, 'probability': 0.9872934818267822}, {'word': ' that', 'start': 67.0, 'end': 67.28, 'probability': 0.9960540533065796}, {'word': ' milliliter.', 'start': 67.28, 'end': 68.04, 'probability': 0.9771544734636942}]}\n",
            "{'id': 18, 'seek': 5340, 'start': 68.6, 'end': 69.24, 'text': ' Models.', 'tokens': [51142, 6583, 1625, 13, 51192], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' Models.', 'start': 68.6, 'end': 69.24, 'probability': 0.9386022090911865}]}\n",
            "{'id': 19, 'seek': 5340, 'start': 69.66, 'end': 72.7, 'text': ' Particularly SVM and Logistic Regression.', 'tokens': [51192, 32281, 31910, 44, 293, 10824, 3142, 4791, 2775, 13, 51370], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' Particularly', 'start': 69.66, 'end': 70.28, 'probability': 0.8889226913452148}, {'word': ' SVM', 'start': 70.28, 'end': 71.24, 'probability': 0.9884111881256104}, {'word': ' and', 'start': 71.24, 'end': 71.42, 'probability': 0.8334113955497742}, {'word': ' Logistic', 'start': 71.42, 'end': 72.02, 'probability': 0.9399620592594147}, {'word': ' Regression.', 'start': 72.02, 'end': 72.7, 'probability': 0.8887357711791992}]}\n",
            "{'id': 20, 'seek': 5340, 'start': 73.36, 'end': 79.9, 'text': ' Can effectively identify key predictors and achieve substantial accuracy in dementia', 'tokens': [51370, 1664, 8659, 5876, 2141, 6069, 830, 293, 4584, 16726, 14170, 294, 31734, 51692], 'temperature': 0.0, 'avg_logprob': -0.3644164800643921, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.01513682771474123, 'words': [{'word': ' Can', 'start': 73.36, 'end': 73.54, 'probability': 0.9235587120056152}, {'word': ' effectively', 'start': 73.54, 'end': 74.3, 'probability': 0.7714557647705078}, {'word': ' identify', 'start': 74.3, 'end': 75.24, 'probability': 0.45465266704559326}, {'word': ' key', 'start': 75.24, 'end': 75.78, 'probability': 0.9881960153579712}, {'word': ' predictors', 'start': 75.78, 'end': 76.44, 'probability': 0.9772602319717407}, {'word': ' and', 'start': 76.44, 'end': 76.6, 'probability': 0.795373797416687}, {'word': ' achieve', 'start': 76.6, 'end': 76.9, 'probability': 0.9919133186340332}, {'word': ' substantial', 'start': 76.9, 'end': 77.72, 'probability': 0.9952827095985413}, {'word': ' accuracy', 'start': 77.72, 'end': 78.42, 'probability': 0.9737869501113892}, {'word': ' in', 'start': 78.42, 'end': 78.94, 'probability': 0.9848694801330566}, {'word': ' dementia', 'start': 78.94, 'end': 79.9, 'probability': 0.32769274711608887}]}\n",
            "{'id': 21, 'seek': 7990, 'start': 79.9, 'end': 80.54, 'text': ' prediction.', 'tokens': [50364, 17630, 13, 50428], 'temperature': 0.0, 'avg_logprob': -0.18374404200801142, 'compression_ratio': 1.4871794871794872, 'no_speech_prob': 0.17853274941444397, 'words': [{'word': ' prediction.', 'start': 79.9, 'end': 80.54, 'probability': 0.392731636762619}]}\n",
            "{'id': 22, 'seek': 7990, 'start': 81.08, 'end': 83.74, 'text': ' The primary aim of this study is to validate.', 'tokens': [50428, 440, 6194, 5939, 295, 341, 2979, 307, 281, 29562, 13, 50594], 'temperature': 0.0, 'avg_logprob': -0.18374404200801142, 'compression_ratio': 1.4871794871794872, 'no_speech_prob': 0.17853274941444397, 'words': [{'word': ' The', 'start': 81.08, 'end': 81.2, 'probability': 0.847435474395752}, {'word': ' primary', 'start': 81.2, 'end': 81.64, 'probability': 0.9964123368263245}, {'word': ' aim', 'start': 81.64, 'end': 82.06, 'probability': 0.9941378831863403}, {'word': ' of', 'start': 82.06, 'end': 82.22, 'probability': 0.9987258315086365}, {'word': ' this', 'start': 82.22, 'end': 82.4, 'probability': 0.9856985211372375}, {'word': ' study', 'start': 82.4, 'end': 82.8, 'probability': 0.9994432330131531}, {'word': ' is', 'start': 82.8, 'end': 83.1, 'probability': 0.9988123178482056}, {'word': ' to', 'start': 83.1, 'end': 83.26, 'probability': 0.9992737174034119}, {'word': ' validate.', 'start': 83.26, 'end': 83.74, 'probability': 0.996263325214386}]}\n",
            "{'id': 23, 'seek': 7990, 'start': 84.38, 'end': 90.78, 'text': ' The performance of milliliter models in detecting dementia at an early stage and to identify', 'tokens': [50594, 440, 3389, 295, 1728, 388, 1681, 5245, 294, 40237, 31734, 412, 364, 2440, 3233, 293, 281, 5876, 50910], 'temperature': 0.0, 'avg_logprob': -0.18374404200801142, 'compression_ratio': 1.4871794871794872, 'no_speech_prob': 0.17853274941444397, 'words': [{'word': ' The', 'start': 84.38, 'end': 84.54, 'probability': 0.9799867272377014}, {'word': ' performance', 'start': 84.54, 'end': 85.08, 'probability': 0.9750359654426575}, {'word': ' of', 'start': 85.08, 'end': 85.48, 'probability': 0.9993470311164856}, {'word': ' milliliter', 'start': 85.48, 'end': 86.06, 'probability': 0.8256736596425375}, {'word': ' models', 'start': 86.06, 'end': 86.5, 'probability': 0.9875983595848083}, {'word': ' in', 'start': 86.5, 'end': 86.82, 'probability': 0.9985910058021545}, {'word': ' detecting', 'start': 86.82, 'end': 87.28, 'probability': 0.9981454610824585}, {'word': ' dementia', 'start': 87.28, 'end': 87.96, 'probability': 0.9880355000495911}, {'word': ' at', 'start': 87.96, 'end': 88.24, 'probability': 0.9714520573616028}, {'word': ' an', 'start': 88.24, 'end': 88.38, 'probability': 0.998056948184967}, {'word': ' early', 'start': 88.38, 'end': 88.72, 'probability': 0.9966289401054382}, {'word': ' stage', 'start': 88.72, 'end': 89.68, 'probability': 0.9812047481536865}, {'word': ' and', 'start': 89.68, 'end': 89.98, 'probability': 0.9608391523361206}, {'word': ' to', 'start': 89.98, 'end': 90.12, 'probability': 0.9988337159156799}, {'word': ' identify', 'start': 90.12, 'end': 90.78, 'probability': 0.997158408164978}]}\n",
            "{'id': 24, 'seek': 7990, 'start': 90.78, 'end': 93.26, 'text': ' the most influential health and cognitive.', 'tokens': [50910, 264, 881, 22215, 1585, 293, 15605, 13, 51088], 'temperature': 0.0, 'avg_logprob': -0.18374404200801142, 'compression_ratio': 1.4871794871794872, 'no_speech_prob': 0.17853274941444397, 'words': [{'word': ' the', 'start': 90.78, 'end': 91.04, 'probability': 0.9992067217826843}, {'word': ' most', 'start': 91.04, 'end': 91.32, 'probability': 0.9983664155006409}, {'word': ' influential', 'start': 91.32, 'end': 92.06, 'probability': 0.9982812404632568}, {'word': ' health', 'start': 92.06, 'end': 92.52, 'probability': 0.9979658126831055}, {'word': ' and', 'start': 92.52, 'end': 92.66, 'probability': 0.9015023112297058}, {'word': ' cognitive.', 'start': 92.66, 'end': 93.26, 'probability': 0.9920693635940552}]}\n",
            "{'id': 25, 'seek': 7990, 'start': 93.92, 'end': 96.48, 'text': ' Factors contributing to dementia risk.', 'tokens': [51088, 33375, 830, 19270, 281, 31734, 3148, 13, 51198], 'temperature': 0.0, 'avg_logprob': -0.18374404200801142, 'compression_ratio': 1.4871794871794872, 'no_speech_prob': 0.17853274941444397, 'words': [{'word': ' Factors', 'start': 93.92, 'end': 94.44, 'probability': 0.7736871242523193}, {'word': ' contributing', 'start': 94.44, 'end': 95.1, 'probability': 0.9971768856048584}, {'word': ' to', 'start': 95.1, 'end': 95.46, 'probability': 0.9990082383155823}, {'word': ' dementia', 'start': 95.46, 'end': 95.78, 'probability': 0.9955280423164368}, {'word': ' risk.', 'start': 95.78, 'end': 96.48, 'probability': 0.9913157224655151}]}\n"
          ]
        }
      ],
      "source": [
        "for each in result['segments']:\n",
        "  print (each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lzh_-nhgBeSz"
      },
      "outputs": [],
      "source": [
        "wordlevel_info = []\n",
        "\n",
        "for each in result['segments']:\n",
        "  words = each['words']\n",
        "  for word in words:\n",
        "    # print (word['word'], \"  \",word['start'],\" - \",word['end'])\n",
        "    wordlevel_info.append({'word':word['word'].strip(),'start':word['start'],'end':word['end']})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgQgEDZRBjBK",
        "outputId": "05c25a08-011b-4888-e4cc-888ab4ad7ea3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'word': 'Key', 'start': 0.0, 'end': 0.26},\n",
              " {'word': 'insights', 'start': 0.26, 'end': 0.74},\n",
              " {'word': 'from', 'start': 0.74, 'end': 1.14},\n",
              " {'word': 'the', 'start': 1.14, 'end': 1.34},\n",
              " {'word': 'paper,', 'start': 1.34, 'end': 1.7},\n",
              " {'word': 'Comprehensive', 'start': 2.34, 'end': 3.14},\n",
              " {'word': 'Health', 'start': 3.14, 'end': 3.42},\n",
              " {'word': 'Data', 'start': 3.42, 'end': 3.92},\n",
              " {'word': 'Analysis', 'start': 3.92, 'end': 4.42},\n",
              " {'word': 'for', 'start': 4.42, 'end': 4.84},\n",
              " {'word': 'Early', 'start': 4.84, 'end': 5.24},\n",
              " {'word': 'Dementure', 'start': 5.24, 'end': 6.5},\n",
              " {'word': 'Diagnosis,', 'start': 6.5, 'end': 7.22},\n",
              " {'word': 'a', 'start': 7.74, 'end': 7.88},\n",
              " {'word': 'Machine', 'start': 7.88, 'end': 8.22},\n",
              " {'word': 'Learning', 'start': 8.22, 'end': 8.68},\n",
              " {'word': 'approach.', 'start': 8.68, 'end': 9.36},\n",
              " {'word': 'J.', 'start': 9.92, 'end': 9.98},\n",
              " {'word': 'Min', 'start': 10.04, 'end': 10.26},\n",
              " {'word': 'Salvi,', 'start': 10.26, 'end': 10.82},\n",
              " {'word': 'Asterisk', 'start': 11.0, 'end': 11.54},\n",
              " {'word': 'Operator,', 'start': 11.54, 'end': 12.2},\n",
              " {'word': 'Agam', 'start': 12.64, 'end': 13.02},\n",
              " {'word': 'Shah,', 'start': 13.02, 'end': 13.28},\n",
              " {'word': 'Asterisk', 'start': 13.86, 'end': 14.6},\n",
              " {'word': 'Operator', 'start': 14.6, 'end': 15.22},\n",
              " {'word': 'Department', 'start': 15.22, 'end': 15.76},\n",
              " {'word': 'of', 'start': 15.76, 'end': 16.16},\n",
              " {'word': 'Computer', 'start': 16.16, 'end': 16.56},\n",
              " {'word': 'Science,', 'start': 16.56, 'end': 17.1},\n",
              " {'word': 'NIRMA', 'start': 17.82, 'end': 18.2},\n",
              " {'word': 'University,', 'start': 18.2, 'end': 19.04},\n",
              " {'word': 'India,', 'start': 19.58, 'end': 20.0},\n",
              " {'word': 'Department', 'start': 20.36, 'end': 21.0},\n",
              " {'word': 'of', 'start': 21.0, 'end': 21.4},\n",
              " {'word': 'Computer', 'start': 21.4, 'end': 21.8},\n",
              " {'word': 'Science,', 'start': 21.8, 'end': 22.44},\n",
              " {'word': 'NIRMA', 'start': 23.0, 'end': 23.36},\n",
              " {'word': 'University,', 'start': 23.36, 'end': 24.16},\n",
              " {'word': 'India,', 'start': 24.76, 'end': 25.16},\n",
              " {'word': 'ABSTRACT.', 'start': 25.66, 'end': 26.5},\n",
              " {'word': 'This', 'start': 26.74, 'end': 27.1},\n",
              " {'word': 'paper', 'start': 27.1, 'end': 27.44},\n",
              " {'word': 'investigates', 'start': 27.44, 'end': 28.46},\n",
              " {'word': 'the', 'start': 28.46, 'end': 28.64},\n",
              " {'word': 'application', 'start': 28.64, 'end': 29.28},\n",
              " {'word': 'of', 'start': 29.28, 'end': 29.54},\n",
              " {'word': 'machine.', 'start': 29.54, 'end': 29.92},\n",
              " {'word': 'Learning.', 'start': 30.68, 'end': 31.04},\n",
              " {'word': 'Milliliter.', 'start': 31.58, 'end': 32.26},\n",
              " {'word': 'Models', 'start': 32.7, 'end': 33.18},\n",
              " {'word': 'to', 'start': 33.18, 'end': 33.36},\n",
              " {'word': 'predict', 'start': 33.36, 'end': 33.68},\n",
              " {'word': 'dementia', 'start': 33.68, 'end': 34.4},\n",
              " {'word': 'diagnosis', 'start': 34.4, 'end': 35.1},\n",
              " {'word': 'using', 'start': 35.1, 'end': 35.74},\n",
              " {'word': 'a', 'start': 35.74, 'end': 35.96},\n",
              " {'word': 'Comprehensive', 'start': 35.96, 'end': 37.2},\n",
              " {'word': 'Health', 'start': 37.2, 'end': 37.5},\n",
              " {'word': 'Data', 'start': 37.5, 'end': 37.84},\n",
              " {'word': 'Set.', 'start': 37.84, 'end': 38.26},\n",
              " {'word': 'The', 'start': 38.56, 'end': 38.82},\n",
              " {'word': 'data', 'start': 38.82, 'end': 39.12},\n",
              " {'word': 'set', 'start': 39.12, 'end': 39.58},\n",
              " {'word': 'includes', 'start': 39.58, 'end': 39.94},\n",
              " {'word': 'key', 'start': 39.94, 'end': 40.36},\n",
              " {'word': 'health', 'start': 40.36, 'end': 40.72},\n",
              " {'word': '-related', 'start': 40.72, 'end': 41.06},\n",
              " {'word': 'features', 'start': 41.06, 'end': 41.6},\n",
              " {'word': 'such', 'start': 41.6, 'end': 42.04},\n",
              " {'word': 'as', 'start': 42.04, 'end': 42.26},\n",
              " {'word': 'diabetic', 'start': 42.26, 'end': 42.7},\n",
              " {'word': 'status,', 'start': 42.7, 'end': 43.38},\n",
              " {'word': 'heart', 'start': 44.14, 'end': 44.34},\n",
              " {'word': 'rate,', 'start': 44.34, 'end': 44.74},\n",
              " {'word': 'blood', 'start': 45.22, 'end': 45.48},\n",
              " {'word': 'oxygen,', 'start': 45.48, 'end': 46.14},\n",
              " {'word': 'levels,', 'start': 46.74, 'end': 47.1},\n",
              " {'word': 'body', 'start': 47.68, 'end': 48.1},\n",
              " {'word': 'temperature,', 'start': 48.1, 'end': 48.76},\n",
              " {'word': 'cognitive', 'start': 49.26, 'end': 49.64},\n",
              " {'word': 'test', 'start': 49.64, 'end': 50.26},\n",
              " {'word': 'scores,', 'start': 50.26, 'end': 50.8},\n",
              " {'word': 'and', 'start': 51.12, 'end': 51.48},\n",
              " {'word': 'lifestyle.', 'start': 51.48, 'end': 51.86},\n",
              " {'word': 'Factors.', 'start': 52.74, 'end': 53.4},\n",
              " {'word': 'We', 'start': 53.4, 'end': 53.92},\n",
              " {'word': 'employed', 'start': 53.92, 'end': 54.52},\n",
              " {'word': 'milliliter', 'start': 54.52, 'end': 55.16},\n",
              " {'word': 'techniques', 'start': 55.16, 'end': 55.62},\n",
              " {'word': 'to', 'start': 55.62, 'end': 55.94},\n",
              " {'word': 'predict', 'start': 55.94, 'end': 56.26},\n",
              " {'word': 'dementia', 'start': 56.26, 'end': 56.94},\n",
              " {'word': 'onset.', 'start': 56.94, 'end': 57.48},\n",
              " {'word': 'Leveraging', 'start': 58.24, 'end': 58.84},\n",
              " {'word': 'algorithms', 'start': 58.84, 'end': 59.52},\n",
              " {'word': 'such', 'start': 59.52, 'end': 59.98},\n",
              " {'word': 'as', 'start': 59.98, 'end': 60.12},\n",
              " {'word': 'support', 'start': 60.12, 'end': 60.52},\n",
              " {'word': 'vector', 'start': 60.52, 'end': 61.0},\n",
              " {'word': 'machines.', 'start': 61.0, 'end': 61.58},\n",
              " {'word': 'SVM.', 'start': 62.24, 'end': 63.12},\n",
              " {'word': 'And', 'start': 63.54, 'end': 63.74},\n",
              " {'word': 'Logistic', 'start': 63.74, 'end': 64.34},\n",
              " {'word': 'Regression.', 'start': 64.34, 'end': 65.08},\n",
              " {'word': 'Our', 'start': 65.62, 'end': 65.76},\n",
              " {'word': 'findings', 'start': 65.76, 'end': 66.2},\n",
              " {'word': 'demonstrate', 'start': 66.2, 'end': 67.0},\n",
              " {'word': 'that', 'start': 67.0, 'end': 67.28},\n",
              " {'word': 'milliliter.', 'start': 67.28, 'end': 68.04},\n",
              " {'word': 'Models.', 'start': 68.6, 'end': 69.24},\n",
              " {'word': 'Particularly', 'start': 69.66, 'end': 70.28},\n",
              " {'word': 'SVM', 'start': 70.28, 'end': 71.24},\n",
              " {'word': 'and', 'start': 71.24, 'end': 71.42},\n",
              " {'word': 'Logistic', 'start': 71.42, 'end': 72.02},\n",
              " {'word': 'Regression.', 'start': 72.02, 'end': 72.7},\n",
              " {'word': 'Can', 'start': 73.36, 'end': 73.54},\n",
              " {'word': 'effectively', 'start': 73.54, 'end': 74.3},\n",
              " {'word': 'identify', 'start': 74.3, 'end': 75.24},\n",
              " {'word': 'key', 'start': 75.24, 'end': 75.78},\n",
              " {'word': 'predictors', 'start': 75.78, 'end': 76.44},\n",
              " {'word': 'and', 'start': 76.44, 'end': 76.6},\n",
              " {'word': 'achieve', 'start': 76.6, 'end': 76.9},\n",
              " {'word': 'substantial', 'start': 76.9, 'end': 77.72},\n",
              " {'word': 'accuracy', 'start': 77.72, 'end': 78.42},\n",
              " {'word': 'in', 'start': 78.42, 'end': 78.94},\n",
              " {'word': 'dementia', 'start': 78.94, 'end': 79.9},\n",
              " {'word': 'prediction.', 'start': 79.9, 'end': 80.54},\n",
              " {'word': 'The', 'start': 81.08, 'end': 81.2},\n",
              " {'word': 'primary', 'start': 81.2, 'end': 81.64},\n",
              " {'word': 'aim', 'start': 81.64, 'end': 82.06},\n",
              " {'word': 'of', 'start': 82.06, 'end': 82.22},\n",
              " {'word': 'this', 'start': 82.22, 'end': 82.4},\n",
              " {'word': 'study', 'start': 82.4, 'end': 82.8},\n",
              " {'word': 'is', 'start': 82.8, 'end': 83.1},\n",
              " {'word': 'to', 'start': 83.1, 'end': 83.26},\n",
              " {'word': 'validate.', 'start': 83.26, 'end': 83.74},\n",
              " {'word': 'The', 'start': 84.38, 'end': 84.54},\n",
              " {'word': 'performance', 'start': 84.54, 'end': 85.08},\n",
              " {'word': 'of', 'start': 85.08, 'end': 85.48},\n",
              " {'word': 'milliliter', 'start': 85.48, 'end': 86.06},\n",
              " {'word': 'models', 'start': 86.06, 'end': 86.5},\n",
              " {'word': 'in', 'start': 86.5, 'end': 86.82},\n",
              " {'word': 'detecting', 'start': 86.82, 'end': 87.28},\n",
              " {'word': 'dementia', 'start': 87.28, 'end': 87.96},\n",
              " {'word': 'at', 'start': 87.96, 'end': 88.24},\n",
              " {'word': 'an', 'start': 88.24, 'end': 88.38},\n",
              " {'word': 'early', 'start': 88.38, 'end': 88.72},\n",
              " {'word': 'stage', 'start': 88.72, 'end': 89.68},\n",
              " {'word': 'and', 'start': 89.68, 'end': 89.98},\n",
              " {'word': 'to', 'start': 89.98, 'end': 90.12},\n",
              " {'word': 'identify', 'start': 90.12, 'end': 90.78},\n",
              " {'word': 'the', 'start': 90.78, 'end': 91.04},\n",
              " {'word': 'most', 'start': 91.04, 'end': 91.32},\n",
              " {'word': 'influential', 'start': 91.32, 'end': 92.06},\n",
              " {'word': 'health', 'start': 92.06, 'end': 92.52},\n",
              " {'word': 'and', 'start': 92.52, 'end': 92.66},\n",
              " {'word': 'cognitive.', 'start': 92.66, 'end': 93.26},\n",
              " {'word': 'Factors', 'start': 93.92, 'end': 94.44},\n",
              " {'word': 'contributing', 'start': 94.44, 'end': 95.1},\n",
              " {'word': 'to', 'start': 95.1, 'end': 95.46},\n",
              " {'word': 'dementia', 'start': 95.46, 'end': 95.78},\n",
              " {'word': 'risk.', 'start': 95.78, 'end': 96.48}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordlevel_info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-4XVG5S1Bks9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('data.json', 'w') as f:\n",
        "    json.dump(wordlevel_info, f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vlGjRh2mBoGo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('data.json', 'r') as f:\n",
        "    wordlevel_info_modified = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqiGFmIhBqpi",
        "outputId": "7a186db6-2a0c-4017-c154-bba3b350a9e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'word': 'Imagine', 'start': 0.0, 'end': 0.36},\n",
              " {'word': 'a', 'start': 0.36, 'end': 0.76},\n",
              " {'word': 'world', 'start': 0.76, 'end': 1.04},\n",
              " {'word': 'where', 'start': 1.04, 'end': 1.38},\n",
              " {'word': 'iModels', 'start': 1.38, 'end': 2.16},\n",
              " {'word': 'can', 'start': 2.16, 'end': 2.38},\n",
              " {'word': 'be', 'start': 2.38, 'end': 2.58},\n",
              " {'word': 'trained', 'start': 2.58, 'end': 2.88},\n",
              " {'word': 'on', 'start': 2.88, 'end': 3.14},\n",
              " {'word': 'data', 'start': 3.14, 'end': 3.48},\n",
              " {'word': 'from', 'start': 3.48, 'end': 3.78},\n",
              " {'word': 'millions', 'start': 3.78, 'end': 4.14},\n",
              " {'word': 'of', 'start': 4.14, 'end': 4.46},\n",
              " {'word': 'devices', 'start': 4.46, 'end': 4.92},\n",
              " {'word': 'without.', 'start': 4.92, 'end': 5.6},\n",
              " {'word': 'Compromising', 'start': 6.480000000000002, 'end': 7.26},\n",
              " {'word': 'user', 'start': 7.26, 'end': 7.72},\n",
              " {'word': 'privacy.', 'start': 7.72, 'end': 8.24},\n",
              " {'word': \"That's\", 'start': 8.72, 'end': 9.12},\n",
              " {'word': 'the', 'start': 9.12, 'end': 9.26},\n",
              " {'word': 'power', 'start': 9.26, 'end': 9.56},\n",
              " {'word': 'of', 'start': 9.56, 'end': 9.84},\n",
              " {'word': 'federated', 'start': 9.84, 'end': 10.46},\n",
              " {'word': 'learning.', 'start': 10.46, 'end': 10.92},\n",
              " {'word': 'This', 'start': 11.48, 'end': 11.82},\n",
              " {'word': 'game', 'start': 11.82, 'end': 12.06},\n",
              " {'word': 'changing', 'start': 12.06, 'end': 12.58},\n",
              " {'word': 'approach', 'start': 12.58, 'end': 13.08},\n",
              " {'word': 'allows', 'start': 13.08, 'end': 13.52},\n",
              " {'word': 'us', 'start': 13.52, 'end': 13.8},\n",
              " {'word': 'to', 'start': 13.8, 'end': 14.0},\n",
              " {'word': 'train', 'start': 14.0, 'end': 14.3},\n",
              " {'word': 'models', 'start': 14.3, 'end': 14.74},\n",
              " {'word': 'locally', 'start': 14.74, 'end': 15.32},\n",
              " {'word': 'on', 'start': 15.32, 'end': 15.64},\n",
              " {'word': 'each', 'start': 15.64, 'end': 15.92},\n",
              " {'word': 'device', 'start': 15.92, 'end': 16.32},\n",
              " {'word': 'and', 'start': 16.32, 'end': 16.66},\n",
              " {'word': 'share', 'start': 16.66, 'end': 16.92},\n",
              " {'word': 'only', 'start': 16.92, 'end': 17.28},\n",
              " {'word': 'K.', 'start': 17.28, 'end': 17.62},\n",
              " {'word': 'Updates.', 'start': 18.38, 'end': 19.16},\n",
              " {'word': 'Protecting', 'start': 19.64, 'end': 20.28},\n",
              " {'word': 'sensitive', 'start': 20.28, 'end': 20.8},\n",
              " {'word': 'user', 'start': 20.8, 'end': 21.26},\n",
              " {'word': 'data', 'start': 21.26, 'end': 21.72},\n",
              " {'word': 'and', 'start': 21.72, 'end': 21.96},\n",
              " {'word': 'reducing', 'start': 21.96, 'end': 22.32},\n",
              " {'word': 'communication', 'start': 22.32, 'end': 23.12},\n",
              " {'word': 'costs.', 'start': 23.12, 'end': 23.94},\n",
              " {'word': 'Not', 'start': 24.46, 'end': 24.64},\n",
              " {'word': 'only', 'start': 24.64, 'end': 25.02},\n",
              " {'word': 'does', 'start': 25.02, 'end': 25.26},\n",
              " {'word': 'federated', 'start': 25.26, 'end': 25.92},\n",
              " {'word': 'learning.', 'start': 25.92, 'end': 26.42},\n",
              " {'word': 'Prioritize', 'start': 27.44, 'end': 28.28},\n",
              " {'word': 'user', 'start': 28.28, 'end': 28.64},\n",
              " {'word': 'privacy,', 'start': 28.64, 'end': 29.16},\n",
              " {'word': 'but', 'start': 29.58, 'end': 29.8},\n",
              " {'word': 'it', 'start': 29.8, 'end': 29.96},\n",
              " {'word': 'also', 'start': 29.96, 'end': 30.38},\n",
              " {'word': 'leads', 'start': 30.38, 'end': 30.62},\n",
              " {'word': 'to', 'start': 30.62, 'end': 30.94},\n",
              " {'word': 'faster', 'start': 30.94, 'end': 31.22},\n",
              " {'word': 'training', 'start': 31.22, 'end': 31.8},\n",
              " {'word': 'times', 'start': 31.8, 'end': 32.3},\n",
              " {'word': 'and', 'start': 32.3, 'end': 32.48},\n",
              " {'word': 'improved', 'start': 32.48, 'end': 32.96},\n",
              " {'word': 'model', 'start': 32.96, 'end': 33.38},\n",
              " {'word': 'performance.', 'start': 33.38, 'end': 33.98},\n",
              " {'word': \"It's\", 'start': 34.98, 'end': 35.4},\n",
              " {'word': 'a', 'start': 35.4, 'end': 35.5},\n",
              " {'word': 'win', 'start': 35.5, 'end': 35.74},\n",
              " {'word': '-win', 'start': 35.74, 'end': 36.0},\n",
              " {'word': '-win', 'start': 36.0, 'end': 36.26},\n",
              " {'word': 'for', 'start': 36.26, 'end': 36.5},\n",
              " {'word': 'users,', 'start': 36.5, 'end': 36.88},\n",
              " {'word': 'developers', 'start': 37.74, 'end': 38.3},\n",
              " {'word': 'and', 'start': 38.3, 'end': 39.16},\n",
              " {'word': 'the', 'start': 39.16, 'end': 39.4},\n",
              " {'word': 'environment.', 'start': 39.4, 'end': 40.06},\n",
              " {'word': 'Our', 'start': 40.58, 'end': 40.78},\n",
              " {'word': 'algorithms', 'start': 40.78, 'end': 41.4},\n",
              " {'word': 'like', 'start': 41.86, 'end': 42.28},\n",
              " {'word': 'FedAVG', 'start': 42.28, 'end': 43.38},\n",
              " {'word': 'and', 'start': 43.38, 'end': 43.64},\n",
              " {'word': 'FedSGD.', 'start': 43.64, 'end': 44.68},\n",
              " {'word': 'Combine', 'start': 45.28, 'end': 45.7},\n",
              " {'word': 'models', 'start': 45.7, 'end': 46.16},\n",
              " {'word': 'from', 'start': 46.16, 'end': 46.48},\n",
              " {'word': 'multiple', 'start': 46.48, 'end': 46.96},\n",
              " {'word': 'clients', 'start': 46.96, 'end': 47.5},\n",
              " {'word': 'to', 'start': 47.5, 'end': 47.82},\n",
              " {'word': 'achieve', 'start': 47.82, 'end': 48.18},\n",
              " {'word': 'better', 'start': 48.18, 'end': 48.58},\n",
              " {'word': 'performance.', 'start': 48.58, 'end': 49.18},\n",
              " {'word': 'With', 'start': 49.620000000000005, 'end': 50.1},\n",
              " {'word': 'impressive', 'start': 50.1, 'end': 50.78},\n",
              " {'word': 'results,', 'start': 50.78, 'end': 51.54},\n",
              " {'word': 'FedAVG', 'start': 52.0, 'end': 52.82},\n",
              " {'word': 'has', 'start': 52.82, 'end': 53.14},\n",
              " {'word': 'outperformed', 'start': 53.14, 'end': 53.96},\n",
              " {'word': 'FedSGD', 'start': 53.96, 'end': 54.96},\n",
              " {'word': 'in', 'start': 54.96, 'end': 55.22},\n",
              " {'word': 'many', 'start': 55.22, 'end': 55.5},\n",
              " {'word': 'cases.', 'start': 55.5, 'end': 56.04},\n",
              " {'word': 'Achieving', 'start': 56.92, 'end': 57.48},\n",
              " {'word': 'higher', 'start': 57.48, 'end': 57.96},\n",
              " {'word': 'accuracy', 'start': 57.96, 'end': 58.52},\n",
              " {'word': 'and', 'start': 58.52, 'end': 58.92},\n",
              " {'word': 'faster', 'start': 58.92, 'end': 59.4},\n",
              " {'word': 'convergence.', 'start': 59.4, 'end': 60.04},\n",
              " {'word': 'As', 'start': 60.68, 'end': 60.88},\n",
              " {'word': 'we', 'start': 60.88, 'end': 61.04},\n",
              " {'word': 'move', 'start': 61.04, 'end': 61.32},\n",
              " {'word': 'forward,', 'start': 61.32, 'end': 61.92},\n",
              " {'word': 'we', 'start': 62.46, 'end': 62.6},\n",
              " {'word': 'are', 'start': 62.6, 'end': 62.68},\n",
              " {'word': 'working', 'start': 62.68, 'end': 63.04},\n",
              " {'word': 'to', 'start': 63.04, 'end': 63.26},\n",
              " {'word': 'develop', 'start': 63.26, 'end': 63.58},\n",
              " {'word': 'stronger', 'start': 63.58, 'end': 64.06},\n",
              " {'word': 'privacy', 'start': 64.06, 'end': 64.76},\n",
              " {'word': 'guarantees', 'start': 64.76, 'end': 65.38},\n",
              " {'word': 'and', 'start': 65.38, 'end': 65.72},\n",
              " {'word': 'improve', 'start': 65.72, 'end': 66.14},\n",
              " {'word': 'scalability', 'start': 66.14, 'end': 67.02},\n",
              " {'word': 'and', 'start': 67.02, 'end': 67.28},\n",
              " {'word': 'efficiency', 'start': 67.28, 'end': 67.74},\n",
              " {'word': 'for.', 'start': 67.74, 'end': 68.26},\n",
              " {'word': 'Large', 'start': 69.14, 'end': 69.52},\n",
              " {'word': '-scale', 'start': 69.52, 'end': 69.88},\n",
              " {'word': 'applications.', 'start': 69.88, 'end': 70.68},\n",
              " {'word': 'The', 'start': 71.3, 'end': 71.48},\n",
              " {'word': 'potential', 'start': 71.48, 'end': 72.04},\n",
              " {'word': 'of', 'start': 72.04, 'end': 72.34},\n",
              " {'word': 'federated', 'start': 72.34, 'end': 72.98},\n",
              " {'word': 'learning', 'start': 72.98, 'end': 73.42},\n",
              " {'word': 'is', 'start': 73.42, 'end': 73.74},\n",
              " {'word': 'vast.', 'start': 73.74, 'end': 74.26},\n",
              " {'word': 'With', 'start': 74.74, 'end': 74.96},\n",
              " {'word': 'the', 'start': 74.96, 'end': 75.14},\n",
              " {'word': 'power', 'start': 75.14, 'end': 75.46},\n",
              " {'word': 'to', 'start': 75.46, 'end': 75.68},\n",
              " {'word': 'transform', 'start': 75.68, 'end': 76.28},\n",
              " {'word': 'industries', 'start': 76.28, 'end': 76.96},\n",
              " {'word': 'like', 'start': 76.96, 'end': 77.34},\n",
              " {'word': 'healthcare,', 'start': 77.34, 'end': 77.86},\n",
              " {'word': 'finance', 'start': 78.56, 'end': 78.98},\n",
              " {'word': 'and', 'start': 78.98, 'end': 79.88},\n",
              " {'word': 'education.', 'start': 79.88, 'end': 80.64},\n",
              " {'word': 'This', 'start': 81.14, 'end': 81.5},\n",
              " {'word': 'decentralized,', 'start': 81.5, 'end': 82.34},\n",
              " {'word': 'private', 'start': 83.14, 'end': 83.56},\n",
              " {'word': 'and', 'start': 83.56, 'end': 84.28},\n",
              " {'word': 'efficient', 'start': 84.28, 'end': 84.8},\n",
              " {'word': 'approach', 'start': 84.8, 'end': 85.32},\n",
              " {'word': 'to', 'start': 85.32, 'end': 85.6},\n",
              " {'word': 'machine', 'start': 85.6, 'end': 85.92},\n",
              " {'word': 'learning', 'start': 85.92, 'end': 86.4},\n",
              " {'word': 'has', 'start': 86.4, 'end': 86.7},\n",
              " {'word': 'the', 'start': 86.7, 'end': 86.84},\n",
              " {'word': 'potential', 'start': 86.84, 'end': 87.3},\n",
              " {'word': 'to', 'start': 87.3, 'end': 87.66},\n",
              " {'word': 'revolutionize', 'start': 87.66, 'end': 88.54},\n",
              " {'word': 'the', 'start': 88.54, 'end': 88.76},\n",
              " {'word': 'way', 'start': 88.76, 'end': 88.98},\n",
              " {'word': 'we', 'start': 88.98, 'end': 89.16},\n",
              " {'word': 'live', 'start': 89.16, 'end': 89.5},\n",
              " {'word': 'in.', 'start': 89.5, 'end': 89.74},\n",
              " {'word': 'Work.', 'start': 90.56, 'end': 90.94},\n",
              " {'word': \"Let's\", 'start': 91.42, 'end': 91.82},\n",
              " {'word': 'harness', 'start': 91.82, 'end': 92.06},\n",
              " {'word': 'its', 'start': 92.06, 'end': 92.36},\n",
              " {'word': 'potential', 'start': 92.36, 'end': 93.0},\n",
              " {'word': 'and', 'start': 93.0, 'end': 93.22},\n",
              " {'word': 'create', 'start': 93.22, 'end': 93.54},\n",
              " {'word': 'a', 'start': 93.54, 'end': 93.78},\n",
              " {'word': 'future', 'start': 93.78, 'end': 94.2},\n",
              " {'word': 'where', 'start': 94.2, 'end': 94.54},\n",
              " {'word': 'AI', 'start': 94.54, 'end': 94.88},\n",
              " {'word': 'benefits', 'start': 94.88, 'end': 95.34},\n",
              " {'word': 'everyone', 'start': 95.34, 'end': 96.0},\n",
              " {'word': 'while', 'start': 96.0, 'end': 96.34},\n",
              " {'word': 'protecting.', 'start': 96.34, 'end': 96.94},\n",
              " {'word': 'Individual', 'start': 97.98, 'end': 98.46},\n",
              " {'word': 'privacy', 'start': 98.46, 'end': 99.2},\n",
              " {'word': 'and', 'start': 99.2, 'end': 99.44},\n",
              " {'word': 'security.', 'start': 99.44, 'end': 100.1}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordlevel_info_modified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "brjD1cdGBtG4"
      },
      "outputs": [],
      "source": [
        "def split_text_into_lines(data):\n",
        "\n",
        "    MaxChars = 80\n",
        "    #maxduration in seconds\n",
        "    MaxDuration = 3.0\n",
        "    #Split if nothing is spoken (gap) for these many seconds\n",
        "    MaxGap = 1.5\n",
        "\n",
        "    subtitles = []\n",
        "    line = []\n",
        "    line_duration = 0\n",
        "    line_chars = 0\n",
        "\n",
        "\n",
        "    for idx,word_data in enumerate(data):\n",
        "        word = word_data[\"word\"]\n",
        "        start = word_data[\"start\"]\n",
        "        end = word_data[\"end\"]\n",
        "\n",
        "        line.append(word_data)\n",
        "        line_duration += end - start\n",
        "\n",
        "        temp = \" \".join(item[\"word\"] for item in line)\n",
        "\n",
        "\n",
        "        # Check if adding a new word exceeds the maximum character count or duration\n",
        "        new_line_chars = len(temp)\n",
        "\n",
        "        duration_exceeded = line_duration > MaxDuration\n",
        "        chars_exceeded = new_line_chars > MaxChars\n",
        "        if idx>0:\n",
        "          gap = word_data['start'] - data[idx-1]['end']\n",
        "          # print (word,start,end,gap)\n",
        "          maxgap_exceeded = gap > MaxGap\n",
        "        else:\n",
        "          maxgap_exceeded = False\n",
        "\n",
        "\n",
        "        if duration_exceeded or chars_exceeded or maxgap_exceeded:\n",
        "            if line:\n",
        "                subtitle_line = {\n",
        "                    \"word\": \" \".join(item[\"word\"] for item in line),\n",
        "                    \"start\": line[0][\"start\"],\n",
        "                    \"end\": line[-1][\"end\"],\n",
        "                    \"textcontents\": line\n",
        "                }\n",
        "                subtitles.append(subtitle_line)\n",
        "                line = []\n",
        "                line_duration = 0\n",
        "                line_chars = 0\n",
        "\n",
        "\n",
        "    if line:\n",
        "        subtitle_line = {\n",
        "            \"word\": \" \".join(item[\"word\"] for item in line),\n",
        "            \"start\": line[0][\"start\"],\n",
        "            \"end\": line[-1][\"end\"],\n",
        "            \"textcontents\": line\n",
        "        }\n",
        "        subtitles.append(subtitle_line)\n",
        "\n",
        "    return subtitles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdgpud9BwUg",
        "outputId": "99da9a84-8bf2-4536-fba0-196f75ff89f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'word': 'Imagine a world where iModels can be trained on', 'start': 0.0, 'end': 3.14, 'textcontents': [{'word': 'Imagine', 'start': 0.0, 'end': 0.36}, {'word': 'a', 'start': 0.36, 'end': 0.76}, {'word': 'world', 'start': 0.76, 'end': 1.04}, {'word': 'where', 'start': 1.04, 'end': 1.38}, {'word': 'iModels', 'start': 1.38, 'end': 2.16}, {'word': 'can', 'start': 2.16, 'end': 2.38}, {'word': 'be', 'start': 2.38, 'end': 2.58}, {'word': 'trained', 'start': 2.58, 'end': 2.88}, {'word': 'on', 'start': 2.88, 'end': 3.14}]}, {'word': 'data from millions of devices without. Compromising', 'start': 3.14, 'end': 7.26, 'textcontents': [{'word': 'data', 'start': 3.14, 'end': 3.48}, {'word': 'from', 'start': 3.48, 'end': 3.78}, {'word': 'millions', 'start': 3.78, 'end': 4.14}, {'word': 'of', 'start': 4.14, 'end': 4.46}, {'word': 'devices', 'start': 4.46, 'end': 4.92}, {'word': 'without.', 'start': 4.92, 'end': 5.6}, {'word': 'Compromising', 'start': 6.480000000000002, 'end': 7.26}]}, {'word': \"user privacy. That's the power of federated learning.\", 'start': 7.26, 'end': 10.92, 'textcontents': [{'word': 'user', 'start': 7.26, 'end': 7.72}, {'word': 'privacy.', 'start': 7.72, 'end': 8.24}, {'word': \"That's\", 'start': 8.72, 'end': 9.12}, {'word': 'the', 'start': 9.12, 'end': 9.26}, {'word': 'power', 'start': 9.26, 'end': 9.56}, {'word': 'of', 'start': 9.56, 'end': 9.84}, {'word': 'federated', 'start': 9.84, 'end': 10.46}, {'word': 'learning.', 'start': 10.46, 'end': 10.92}]}, {'word': 'This game changing approach allows us to train models', 'start': 11.48, 'end': 14.74, 'textcontents': [{'word': 'This', 'start': 11.48, 'end': 11.82}, {'word': 'game', 'start': 11.82, 'end': 12.06}, {'word': 'changing', 'start': 12.06, 'end': 12.58}, {'word': 'approach', 'start': 12.58, 'end': 13.08}, {'word': 'allows', 'start': 13.08, 'end': 13.52}, {'word': 'us', 'start': 13.52, 'end': 13.8}, {'word': 'to', 'start': 13.8, 'end': 14.0}, {'word': 'train', 'start': 14.0, 'end': 14.3}, {'word': 'models', 'start': 14.3, 'end': 14.74}]}, {'word': 'locally on each device and share only K. Updates.', 'start': 14.74, 'end': 19.16, 'textcontents': [{'word': 'locally', 'start': 14.74, 'end': 15.32}, {'word': 'on', 'start': 15.32, 'end': 15.64}, {'word': 'each', 'start': 15.64, 'end': 15.92}, {'word': 'device', 'start': 15.92, 'end': 16.32}, {'word': 'and', 'start': 16.32, 'end': 16.66}, {'word': 'share', 'start': 16.66, 'end': 16.92}, {'word': 'only', 'start': 16.92, 'end': 17.28}, {'word': 'K.', 'start': 17.28, 'end': 17.62}, {'word': 'Updates.', 'start': 18.38, 'end': 19.16}]}, {'word': 'Protecting sensitive user data and reducing communication', 'start': 19.64, 'end': 23.12, 'textcontents': [{'word': 'Protecting', 'start': 19.64, 'end': 20.28}, {'word': 'sensitive', 'start': 20.28, 'end': 20.8}, {'word': 'user', 'start': 20.8, 'end': 21.26}, {'word': 'data', 'start': 21.26, 'end': 21.72}, {'word': 'and', 'start': 21.72, 'end': 21.96}, {'word': 'reducing', 'start': 21.96, 'end': 22.32}, {'word': 'communication', 'start': 22.32, 'end': 23.12}]}, {'word': 'costs. Not only does federated learning. Prioritize', 'start': 23.12, 'end': 28.28, 'textcontents': [{'word': 'costs.', 'start': 23.12, 'end': 23.94}, {'word': 'Not', 'start': 24.46, 'end': 24.64}, {'word': 'only', 'start': 24.64, 'end': 25.02}, {'word': 'does', 'start': 25.02, 'end': 25.26}, {'word': 'federated', 'start': 25.26, 'end': 25.92}, {'word': 'learning.', 'start': 25.92, 'end': 26.42}, {'word': 'Prioritize', 'start': 27.44, 'end': 28.28}]}, {'word': 'user privacy, but it also leads to faster training', 'start': 28.28, 'end': 31.8, 'textcontents': [{'word': 'user', 'start': 28.28, 'end': 28.64}, {'word': 'privacy,', 'start': 28.64, 'end': 29.16}, {'word': 'but', 'start': 29.58, 'end': 29.8}, {'word': 'it', 'start': 29.8, 'end': 29.96}, {'word': 'also', 'start': 29.96, 'end': 30.38}, {'word': 'leads', 'start': 30.38, 'end': 30.62}, {'word': 'to', 'start': 30.62, 'end': 30.94}, {'word': 'faster', 'start': 30.94, 'end': 31.22}, {'word': 'training', 'start': 31.22, 'end': 31.8}]}, {'word': \"times and improved model performance. It's a win -win\", 'start': 31.8, 'end': 36.0, 'textcontents': [{'word': 'times', 'start': 31.8, 'end': 32.3}, {'word': 'and', 'start': 32.3, 'end': 32.48}, {'word': 'improved', 'start': 32.48, 'end': 32.96}, {'word': 'model', 'start': 32.96, 'end': 33.38}, {'word': 'performance.', 'start': 33.38, 'end': 33.98}, {'word': \"It's\", 'start': 34.98, 'end': 35.4}, {'word': 'a', 'start': 35.4, 'end': 35.5}, {'word': 'win', 'start': 35.5, 'end': 35.74}, {'word': '-win', 'start': 35.74, 'end': 36.0}]}, {'word': '-win for users, developers and the environment.', 'start': 36.0, 'end': 40.06, 'textcontents': [{'word': '-win', 'start': 36.0, 'end': 36.26}, {'word': 'for', 'start': 36.26, 'end': 36.5}, {'word': 'users,', 'start': 36.5, 'end': 36.88}, {'word': 'developers', 'start': 37.74, 'end': 38.3}, {'word': 'and', 'start': 38.3, 'end': 39.16}, {'word': 'the', 'start': 39.16, 'end': 39.4}, {'word': 'environment.', 'start': 39.4, 'end': 40.06}]}, {'word': 'Our algorithms like FedAVG and FedSGD.', 'start': 40.58, 'end': 44.68, 'textcontents': [{'word': 'Our', 'start': 40.58, 'end': 40.78}, {'word': 'algorithms', 'start': 40.78, 'end': 41.4}, {'word': 'like', 'start': 41.86, 'end': 42.28}, {'word': 'FedAVG', 'start': 42.28, 'end': 43.38}, {'word': 'and', 'start': 43.38, 'end': 43.64}, {'word': 'FedSGD.', 'start': 43.64, 'end': 44.68}]}, {'word': 'Combine models from multiple clients to achieve better', 'start': 45.28, 'end': 48.58, 'textcontents': [{'word': 'Combine', 'start': 45.28, 'end': 45.7}, {'word': 'models', 'start': 45.7, 'end': 46.16}, {'word': 'from', 'start': 46.16, 'end': 46.48}, {'word': 'multiple', 'start': 46.48, 'end': 46.96}, {'word': 'clients', 'start': 46.96, 'end': 47.5}, {'word': 'to', 'start': 47.5, 'end': 47.82}, {'word': 'achieve', 'start': 47.82, 'end': 48.18}, {'word': 'better', 'start': 48.18, 'end': 48.58}]}, {'word': 'performance. With impressive results, FedAVG', 'start': 48.58, 'end': 52.82, 'textcontents': [{'word': 'performance.', 'start': 48.58, 'end': 49.18}, {'word': 'With', 'start': 49.620000000000005, 'end': 50.1}, {'word': 'impressive', 'start': 50.1, 'end': 50.78}, {'word': 'results,', 'start': 50.78, 'end': 51.54}, {'word': 'FedAVG', 'start': 52.0, 'end': 52.82}]}, {'word': 'has outperformed FedSGD in many cases.', 'start': 52.82, 'end': 56.04, 'textcontents': [{'word': 'has', 'start': 52.82, 'end': 53.14}, {'word': 'outperformed', 'start': 53.14, 'end': 53.96}, {'word': 'FedSGD', 'start': 53.96, 'end': 54.96}, {'word': 'in', 'start': 54.96, 'end': 55.22}, {'word': 'many', 'start': 55.22, 'end': 55.5}, {'word': 'cases.', 'start': 55.5, 'end': 56.04}]}, {'word': 'Achieving higher accuracy and faster convergence.', 'start': 56.92, 'end': 60.04, 'textcontents': [{'word': 'Achieving', 'start': 56.92, 'end': 57.48}, {'word': 'higher', 'start': 57.48, 'end': 57.96}, {'word': 'accuracy', 'start': 57.96, 'end': 58.52}, {'word': 'and', 'start': 58.52, 'end': 58.92}, {'word': 'faster', 'start': 58.92, 'end': 59.4}, {'word': 'convergence.', 'start': 59.4, 'end': 60.04}]}, {'word': 'As we move forward, we are working to develop stronger privacy', 'start': 60.68, 'end': 64.76, 'textcontents': [{'word': 'As', 'start': 60.68, 'end': 60.88}, {'word': 'we', 'start': 60.88, 'end': 61.04}, {'word': 'move', 'start': 61.04, 'end': 61.32}, {'word': 'forward,', 'start': 61.32, 'end': 61.92}, {'word': 'we', 'start': 62.46, 'end': 62.6}, {'word': 'are', 'start': 62.6, 'end': 62.68}, {'word': 'working', 'start': 62.68, 'end': 63.04}, {'word': 'to', 'start': 63.04, 'end': 63.26}, {'word': 'develop', 'start': 63.26, 'end': 63.58}, {'word': 'stronger', 'start': 63.58, 'end': 64.06}, {'word': 'privacy', 'start': 64.06, 'end': 64.76}]}, {'word': 'guarantees and improve scalability and efficiency for.', 'start': 64.76, 'end': 68.26, 'textcontents': [{'word': 'guarantees', 'start': 64.76, 'end': 65.38}, {'word': 'and', 'start': 65.38, 'end': 65.72}, {'word': 'improve', 'start': 65.72, 'end': 66.14}, {'word': 'scalability', 'start': 66.14, 'end': 67.02}, {'word': 'and', 'start': 67.02, 'end': 67.28}, {'word': 'efficiency', 'start': 67.28, 'end': 67.74}, {'word': 'for.', 'start': 67.74, 'end': 68.26}]}, {'word': 'Large -scale applications. The potential of federated', 'start': 69.14, 'end': 72.98, 'textcontents': [{'word': 'Large', 'start': 69.14, 'end': 69.52}, {'word': '-scale', 'start': 69.52, 'end': 69.88}, {'word': 'applications.', 'start': 69.88, 'end': 70.68}, {'word': 'The', 'start': 71.3, 'end': 71.48}, {'word': 'potential', 'start': 71.48, 'end': 72.04}, {'word': 'of', 'start': 72.04, 'end': 72.34}, {'word': 'federated', 'start': 72.34, 'end': 72.98}]}, {'word': 'learning is vast. With the power to transform industries', 'start': 72.98, 'end': 76.96, 'textcontents': [{'word': 'learning', 'start': 72.98, 'end': 73.42}, {'word': 'is', 'start': 73.42, 'end': 73.74}, {'word': 'vast.', 'start': 73.74, 'end': 74.26}, {'word': 'With', 'start': 74.74, 'end': 74.96}, {'word': 'the', 'start': 74.96, 'end': 75.14}, {'word': 'power', 'start': 75.14, 'end': 75.46}, {'word': 'to', 'start': 75.46, 'end': 75.68}, {'word': 'transform', 'start': 75.68, 'end': 76.28}, {'word': 'industries', 'start': 76.28, 'end': 76.96}]}, {'word': 'like healthcare, finance and education. This', 'start': 76.96, 'end': 81.5, 'textcontents': [{'word': 'like', 'start': 76.96, 'end': 77.34}, {'word': 'healthcare,', 'start': 77.34, 'end': 77.86}, {'word': 'finance', 'start': 78.56, 'end': 78.98}, {'word': 'and', 'start': 78.98, 'end': 79.88}, {'word': 'education.', 'start': 79.88, 'end': 80.64}, {'word': 'This', 'start': 81.14, 'end': 81.5}]}, {'word': 'decentralized, private and efficient approach', 'start': 81.5, 'end': 85.32, 'textcontents': [{'word': 'decentralized,', 'start': 81.5, 'end': 82.34}, {'word': 'private', 'start': 83.14, 'end': 83.56}, {'word': 'and', 'start': 83.56, 'end': 84.28}, {'word': 'efficient', 'start': 84.28, 'end': 84.8}, {'word': 'approach', 'start': 84.8, 'end': 85.32}]}, {'word': 'to machine learning has the potential to revolutionize', 'start': 85.32, 'end': 88.54, 'textcontents': [{'word': 'to', 'start': 85.32, 'end': 85.6}, {'word': 'machine', 'start': 85.6, 'end': 85.92}, {'word': 'learning', 'start': 85.92, 'end': 86.4}, {'word': 'has', 'start': 86.4, 'end': 86.7}, {'word': 'the', 'start': 86.7, 'end': 86.84}, {'word': 'potential', 'start': 86.84, 'end': 87.3}, {'word': 'to', 'start': 87.3, 'end': 87.66}, {'word': 'revolutionize', 'start': 87.66, 'end': 88.54}]}, {'word': \"the way we live in. Work. Let's harness its potential\", 'start': 88.54, 'end': 93.0, 'textcontents': [{'word': 'the', 'start': 88.54, 'end': 88.76}, {'word': 'way', 'start': 88.76, 'end': 88.98}, {'word': 'we', 'start': 88.98, 'end': 89.16}, {'word': 'live', 'start': 89.16, 'end': 89.5}, {'word': 'in.', 'start': 89.5, 'end': 89.74}, {'word': 'Work.', 'start': 90.56, 'end': 90.94}, {'word': \"Let's\", 'start': 91.42, 'end': 91.82}, {'word': 'harness', 'start': 91.82, 'end': 92.06}, {'word': 'its', 'start': 92.06, 'end': 92.36}, {'word': 'potential', 'start': 92.36, 'end': 93.0}]}, {'word': 'and create a future where AI benefits everyone while', 'start': 93.0, 'end': 96.34, 'textcontents': [{'word': 'and', 'start': 93.0, 'end': 93.22}, {'word': 'create', 'start': 93.22, 'end': 93.54}, {'word': 'a', 'start': 93.54, 'end': 93.78}, {'word': 'future', 'start': 93.78, 'end': 94.2}, {'word': 'where', 'start': 94.2, 'end': 94.54}, {'word': 'AI', 'start': 94.54, 'end': 94.88}, {'word': 'benefits', 'start': 94.88, 'end': 95.34}, {'word': 'everyone', 'start': 95.34, 'end': 96.0}, {'word': 'while', 'start': 96.0, 'end': 96.34}]}, {'word': 'protecting. Individual privacy and security.', 'start': 96.34, 'end': 100.1, 'textcontents': [{'word': 'protecting.', 'start': 96.34, 'end': 96.94}, {'word': 'Individual', 'start': 97.98, 'end': 98.46}, {'word': 'privacy', 'start': 98.46, 'end': 99.2}, {'word': 'and', 'start': 99.2, 'end': 99.44}, {'word': 'security.', 'start': 99.44, 'end': 100.1}]}]\n"
          ]
        }
      ],
      "source": [
        "linelevel_subtitles = split_text_into_lines(wordlevel_info_modified)\n",
        "print (linelevel_subtitles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipzLIaTVCIvQ",
        "outputId": "47f933ac-55f4-4e19-c0ba-6b1823f68c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"word\": \"Key insights from the paper, Comprehensive Health Data\",\n",
            "    \"start\": 0.0,\n",
            "    \"end\": 3.92,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Key\",\n",
            "            \"start\": 0.0,\n",
            "            \"end\": 0.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"insights\",\n",
            "            \"start\": 0.26,\n",
            "            \"end\": 0.74\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"from\",\n",
            "            \"start\": 0.74,\n",
            "            \"end\": 1.14\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"the\",\n",
            "            \"start\": 1.14,\n",
            "            \"end\": 1.34\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"paper,\",\n",
            "            \"start\": 1.34,\n",
            "            \"end\": 1.7\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Comprehensive\",\n",
            "            \"start\": 2.34,\n",
            "            \"end\": 3.14\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Health\",\n",
            "            \"start\": 3.14,\n",
            "            \"end\": 3.42\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Data\",\n",
            "            \"start\": 3.42,\n",
            "            \"end\": 3.92\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Analysis for Early Dementure Diagnosis,\",\n",
            "    \"start\": 3.92,\n",
            "    \"end\": 7.22,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Analysis\",\n",
            "            \"start\": 3.92,\n",
            "            \"end\": 4.42\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"for\",\n",
            "            \"start\": 4.42,\n",
            "            \"end\": 4.84\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Early\",\n",
            "            \"start\": 4.84,\n",
            "            \"end\": 5.24\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Dementure\",\n",
            "            \"start\": 5.24,\n",
            "            \"end\": 6.5\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Diagnosis,\",\n",
            "            \"start\": 6.5,\n",
            "            \"end\": 7.22\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"a Machine Learning approach. J. Min Salvi, Asterisk Operator,\",\n",
            "    \"start\": 7.74,\n",
            "    \"end\": 12.2,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"a\",\n",
            "            \"start\": 7.74,\n",
            "            \"end\": 7.88\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Machine\",\n",
            "            \"start\": 7.88,\n",
            "            \"end\": 8.22\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Learning\",\n",
            "            \"start\": 8.22,\n",
            "            \"end\": 8.68\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"approach.\",\n",
            "            \"start\": 8.68,\n",
            "            \"end\": 9.36\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"J.\",\n",
            "            \"start\": 9.92,\n",
            "            \"end\": 9.98\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Min\",\n",
            "            \"start\": 10.04,\n",
            "            \"end\": 10.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Salvi,\",\n",
            "            \"start\": 10.26,\n",
            "            \"end\": 10.82\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Asterisk\",\n",
            "            \"start\": 11.0,\n",
            "            \"end\": 11.54\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Operator,\",\n",
            "            \"start\": 11.54,\n",
            "            \"end\": 12.2\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Agam Shah, Asterisk Operator Department of Computer\",\n",
            "    \"start\": 12.64,\n",
            "    \"end\": 16.56,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Agam\",\n",
            "            \"start\": 12.64,\n",
            "            \"end\": 13.02\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Shah,\",\n",
            "            \"start\": 13.02,\n",
            "            \"end\": 13.28\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Asterisk\",\n",
            "            \"start\": 13.86,\n",
            "            \"end\": 14.6\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Operator\",\n",
            "            \"start\": 14.6,\n",
            "            \"end\": 15.22\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Department\",\n",
            "            \"start\": 15.22,\n",
            "            \"end\": 15.76\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"of\",\n",
            "            \"start\": 15.76,\n",
            "            \"end\": 16.16\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Computer\",\n",
            "            \"start\": 16.16,\n",
            "            \"end\": 16.56\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Science, NIRMA University, India, Department of\",\n",
            "    \"start\": 16.56,\n",
            "    \"end\": 21.4,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Science,\",\n",
            "            \"start\": 16.56,\n",
            "            \"end\": 17.1\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"NIRMA\",\n",
            "            \"start\": 17.82,\n",
            "            \"end\": 18.2\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"University,\",\n",
            "            \"start\": 18.2,\n",
            "            \"end\": 19.04\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"India,\",\n",
            "            \"start\": 19.58,\n",
            "            \"end\": 20.0\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Department\",\n",
            "            \"start\": 20.36,\n",
            "            \"end\": 21.0\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"of\",\n",
            "            \"start\": 21.0,\n",
            "            \"end\": 21.4\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Computer Science, NIRMA University, India, ABSTRACT.\",\n",
            "    \"start\": 21.4,\n",
            "    \"end\": 26.5,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Computer\",\n",
            "            \"start\": 21.4,\n",
            "            \"end\": 21.8\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Science,\",\n",
            "            \"start\": 21.8,\n",
            "            \"end\": 22.44\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"NIRMA\",\n",
            "            \"start\": 23.0,\n",
            "            \"end\": 23.36\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"University,\",\n",
            "            \"start\": 23.36,\n",
            "            \"end\": 24.16\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"India,\",\n",
            "            \"start\": 24.76,\n",
            "            \"end\": 25.16\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"ABSTRACT.\",\n",
            "            \"start\": 25.66,\n",
            "            \"end\": 26.5\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"This paper investigates the application of machine.\",\n",
            "    \"start\": 26.74,\n",
            "    \"end\": 29.92,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"This\",\n",
            "            \"start\": 26.74,\n",
            "            \"end\": 27.1\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"paper\",\n",
            "            \"start\": 27.1,\n",
            "            \"end\": 27.44\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"investigates\",\n",
            "            \"start\": 27.44,\n",
            "            \"end\": 28.46\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"the\",\n",
            "            \"start\": 28.46,\n",
            "            \"end\": 28.64\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"application\",\n",
            "            \"start\": 28.64,\n",
            "            \"end\": 29.28\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"of\",\n",
            "            \"start\": 29.28,\n",
            "            \"end\": 29.54\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"machine.\",\n",
            "            \"start\": 29.54,\n",
            "            \"end\": 29.92\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Learning. Milliliter. Models to predict dementia diagnosis\",\n",
            "    \"start\": 30.68,\n",
            "    \"end\": 35.1,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Learning.\",\n",
            "            \"start\": 30.68,\n",
            "            \"end\": 31.04\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Milliliter.\",\n",
            "            \"start\": 31.58,\n",
            "            \"end\": 32.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Models\",\n",
            "            \"start\": 32.7,\n",
            "            \"end\": 33.18\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"to\",\n",
            "            \"start\": 33.18,\n",
            "            \"end\": 33.36\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"predict\",\n",
            "            \"start\": 33.36,\n",
            "            \"end\": 33.68\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"dementia\",\n",
            "            \"start\": 33.68,\n",
            "            \"end\": 34.4\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"diagnosis\",\n",
            "            \"start\": 34.4,\n",
            "            \"end\": 35.1\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"using a Comprehensive Health Data Set.\",\n",
            "    \"start\": 35.1,\n",
            "    \"end\": 38.26,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"using\",\n",
            "            \"start\": 35.1,\n",
            "            \"end\": 35.74\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"a\",\n",
            "            \"start\": 35.74,\n",
            "            \"end\": 35.96\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Comprehensive\",\n",
            "            \"start\": 35.96,\n",
            "            \"end\": 37.2\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Health\",\n",
            "            \"start\": 37.2,\n",
            "            \"end\": 37.5\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Data\",\n",
            "            \"start\": 37.5,\n",
            "            \"end\": 37.84\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Set.\",\n",
            "            \"start\": 37.84,\n",
            "            \"end\": 38.26\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"The data set includes key health -related features\",\n",
            "    \"start\": 38.56,\n",
            "    \"end\": 41.6,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"The\",\n",
            "            \"start\": 38.56,\n",
            "            \"end\": 38.82\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"data\",\n",
            "            \"start\": 38.82,\n",
            "            \"end\": 39.12\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"set\",\n",
            "            \"start\": 39.12,\n",
            "            \"end\": 39.58\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"includes\",\n",
            "            \"start\": 39.58,\n",
            "            \"end\": 39.94\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"key\",\n",
            "            \"start\": 39.94,\n",
            "            \"end\": 40.36\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"health\",\n",
            "            \"start\": 40.36,\n",
            "            \"end\": 40.72\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"-related\",\n",
            "            \"start\": 40.72,\n",
            "            \"end\": 41.06\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"features\",\n",
            "            \"start\": 41.06,\n",
            "            \"end\": 41.6\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"such as diabetic status, heart rate, blood oxygen,\",\n",
            "    \"start\": 41.6,\n",
            "    \"end\": 46.14,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"such\",\n",
            "            \"start\": 41.6,\n",
            "            \"end\": 42.04\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"as\",\n",
            "            \"start\": 42.04,\n",
            "            \"end\": 42.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"diabetic\",\n",
            "            \"start\": 42.26,\n",
            "            \"end\": 42.7\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"status,\",\n",
            "            \"start\": 42.7,\n",
            "            \"end\": 43.38\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"heart\",\n",
            "            \"start\": 44.14,\n",
            "            \"end\": 44.34\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"rate,\",\n",
            "            \"start\": 44.34,\n",
            "            \"end\": 44.74\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"blood\",\n",
            "            \"start\": 45.22,\n",
            "            \"end\": 45.48\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"oxygen,\",\n",
            "            \"start\": 45.48,\n",
            "            \"end\": 46.14\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"levels, body temperature, cognitive test scores, and\",\n",
            "    \"start\": 46.74,\n",
            "    \"end\": 51.48,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"levels,\",\n",
            "            \"start\": 46.74,\n",
            "            \"end\": 47.1\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"body\",\n",
            "            \"start\": 47.68,\n",
            "            \"end\": 48.1\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"temperature,\",\n",
            "            \"start\": 48.1,\n",
            "            \"end\": 48.76\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"cognitive\",\n",
            "            \"start\": 49.26,\n",
            "            \"end\": 49.64\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"test\",\n",
            "            \"start\": 49.64,\n",
            "            \"end\": 50.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"scores,\",\n",
            "            \"start\": 50.26,\n",
            "            \"end\": 50.8\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"and\",\n",
            "            \"start\": 51.12,\n",
            "            \"end\": 51.48\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"lifestyle. Factors. We employed milliliter techniques\",\n",
            "    \"start\": 51.48,\n",
            "    \"end\": 55.62,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"lifestyle.\",\n",
            "            \"start\": 51.48,\n",
            "            \"end\": 51.86\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Factors.\",\n",
            "            \"start\": 52.74,\n",
            "            \"end\": 53.4\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"We\",\n",
            "            \"start\": 53.4,\n",
            "            \"end\": 53.92\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"employed\",\n",
            "            \"start\": 53.92,\n",
            "            \"end\": 54.52\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"milliliter\",\n",
            "            \"start\": 54.52,\n",
            "            \"end\": 55.16\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"techniques\",\n",
            "            \"start\": 55.16,\n",
            "            \"end\": 55.62\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"to predict dementia onset. Leveraging algorithms\",\n",
            "    \"start\": 55.62,\n",
            "    \"end\": 59.52,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"to\",\n",
            "            \"start\": 55.62,\n",
            "            \"end\": 55.94\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"predict\",\n",
            "            \"start\": 55.94,\n",
            "            \"end\": 56.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"dementia\",\n",
            "            \"start\": 56.26,\n",
            "            \"end\": 56.94\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"onset.\",\n",
            "            \"start\": 56.94,\n",
            "            \"end\": 57.48\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Leveraging\",\n",
            "            \"start\": 58.24,\n",
            "            \"end\": 58.84\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"algorithms\",\n",
            "            \"start\": 58.84,\n",
            "            \"end\": 59.52\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"such as support vector machines. SVM. And\",\n",
            "    \"start\": 59.52,\n",
            "    \"end\": 63.74,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"such\",\n",
            "            \"start\": 59.52,\n",
            "            \"end\": 59.98\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"as\",\n",
            "            \"start\": 59.98,\n",
            "            \"end\": 60.12\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"support\",\n",
            "            \"start\": 60.12,\n",
            "            \"end\": 60.52\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"vector\",\n",
            "            \"start\": 60.52,\n",
            "            \"end\": 61.0\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"machines.\",\n",
            "            \"start\": 61.0,\n",
            "            \"end\": 61.58\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"SVM.\",\n",
            "            \"start\": 62.24,\n",
            "            \"end\": 63.12\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"And\",\n",
            "            \"start\": 63.54,\n",
            "            \"end\": 63.74\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Logistic Regression. Our findings demonstrate that milliliter.\",\n",
            "    \"start\": 63.74,\n",
            "    \"end\": 68.04,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Logistic\",\n",
            "            \"start\": 63.74,\n",
            "            \"end\": 64.34\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Regression.\",\n",
            "            \"start\": 64.34,\n",
            "            \"end\": 65.08\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Our\",\n",
            "            \"start\": 65.62,\n",
            "            \"end\": 65.76\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"findings\",\n",
            "            \"start\": 65.76,\n",
            "            \"end\": 66.2\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"demonstrate\",\n",
            "            \"start\": 66.2,\n",
            "            \"end\": 67.0\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"that\",\n",
            "            \"start\": 67.0,\n",
            "            \"end\": 67.28\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"milliliter.\",\n",
            "            \"start\": 67.28,\n",
            "            \"end\": 68.04\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Models. Particularly SVM and Logistic Regression.\",\n",
            "    \"start\": 68.6,\n",
            "    \"end\": 72.7,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Models.\",\n",
            "            \"start\": 68.6,\n",
            "            \"end\": 69.24\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Particularly\",\n",
            "            \"start\": 69.66,\n",
            "            \"end\": 70.28\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"SVM\",\n",
            "            \"start\": 70.28,\n",
            "            \"end\": 71.24\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"and\",\n",
            "            \"start\": 71.24,\n",
            "            \"end\": 71.42\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Logistic\",\n",
            "            \"start\": 71.42,\n",
            "            \"end\": 72.02\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Regression.\",\n",
            "            \"start\": 72.02,\n",
            "            \"end\": 72.7\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"Can effectively identify key predictors\",\n",
            "    \"start\": 73.36,\n",
            "    \"end\": 76.44,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"Can\",\n",
            "            \"start\": 73.36,\n",
            "            \"end\": 73.54\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"effectively\",\n",
            "            \"start\": 73.54,\n",
            "            \"end\": 74.3\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"identify\",\n",
            "            \"start\": 74.3,\n",
            "            \"end\": 75.24\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"key\",\n",
            "            \"start\": 75.24,\n",
            "            \"end\": 75.78\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"predictors\",\n",
            "            \"start\": 75.78,\n",
            "            \"end\": 76.44\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"and achieve substantial accuracy in dementia\",\n",
            "    \"start\": 76.44,\n",
            "    \"end\": 79.9,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"and\",\n",
            "            \"start\": 76.44,\n",
            "            \"end\": 76.6\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"achieve\",\n",
            "            \"start\": 76.6,\n",
            "            \"end\": 76.9\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"substantial\",\n",
            "            \"start\": 76.9,\n",
            "            \"end\": 77.72\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"accuracy\",\n",
            "            \"start\": 77.72,\n",
            "            \"end\": 78.42\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"in\",\n",
            "            \"start\": 78.42,\n",
            "            \"end\": 78.94\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"dementia\",\n",
            "            \"start\": 78.94,\n",
            "            \"end\": 79.9\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"prediction. The primary aim of this study is to validate.\",\n",
            "    \"start\": 79.9,\n",
            "    \"end\": 83.74,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"prediction.\",\n",
            "            \"start\": 79.9,\n",
            "            \"end\": 80.54\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"The\",\n",
            "            \"start\": 81.08,\n",
            "            \"end\": 81.2\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"primary\",\n",
            "            \"start\": 81.2,\n",
            "            \"end\": 81.64\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"aim\",\n",
            "            \"start\": 81.64,\n",
            "            \"end\": 82.06\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"of\",\n",
            "            \"start\": 82.06,\n",
            "            \"end\": 82.22\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"this\",\n",
            "            \"start\": 82.22,\n",
            "            \"end\": 82.4\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"study\",\n",
            "            \"start\": 82.4,\n",
            "            \"end\": 82.8\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"is\",\n",
            "            \"start\": 82.8,\n",
            "            \"end\": 83.1\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"to\",\n",
            "            \"start\": 83.1,\n",
            "            \"end\": 83.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"validate.\",\n",
            "            \"start\": 83.26,\n",
            "            \"end\": 83.74\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"The performance of milliliter models in detecting dementia\",\n",
            "    \"start\": 84.38,\n",
            "    \"end\": 87.96,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"The\",\n",
            "            \"start\": 84.38,\n",
            "            \"end\": 84.54\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"performance\",\n",
            "            \"start\": 84.54,\n",
            "            \"end\": 85.08\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"of\",\n",
            "            \"start\": 85.08,\n",
            "            \"end\": 85.48\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"milliliter\",\n",
            "            \"start\": 85.48,\n",
            "            \"end\": 86.06\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"models\",\n",
            "            \"start\": 86.06,\n",
            "            \"end\": 86.5\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"in\",\n",
            "            \"start\": 86.5,\n",
            "            \"end\": 86.82\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"detecting\",\n",
            "            \"start\": 86.82,\n",
            "            \"end\": 87.28\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"dementia\",\n",
            "            \"start\": 87.28,\n",
            "            \"end\": 87.96\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"at an early stage and to identify the\",\n",
            "    \"start\": 87.96,\n",
            "    \"end\": 91.04,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"at\",\n",
            "            \"start\": 87.96,\n",
            "            \"end\": 88.24\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"an\",\n",
            "            \"start\": 88.24,\n",
            "            \"end\": 88.38\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"early\",\n",
            "            \"start\": 88.38,\n",
            "            \"end\": 88.72\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"stage\",\n",
            "            \"start\": 88.72,\n",
            "            \"end\": 89.68\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"and\",\n",
            "            \"start\": 89.68,\n",
            "            \"end\": 89.98\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"to\",\n",
            "            \"start\": 89.98,\n",
            "            \"end\": 90.12\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"identify\",\n",
            "            \"start\": 90.12,\n",
            "            \"end\": 90.78\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"the\",\n",
            "            \"start\": 90.78,\n",
            "            \"end\": 91.04\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"most influential health and cognitive. Factors contributing\",\n",
            "    \"start\": 91.04,\n",
            "    \"end\": 95.1,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"most\",\n",
            "            \"start\": 91.04,\n",
            "            \"end\": 91.32\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"influential\",\n",
            "            \"start\": 91.32,\n",
            "            \"end\": 92.06\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"health\",\n",
            "            \"start\": 92.06,\n",
            "            \"end\": 92.52\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"and\",\n",
            "            \"start\": 92.52,\n",
            "            \"end\": 92.66\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"cognitive.\",\n",
            "            \"start\": 92.66,\n",
            "            \"end\": 93.26\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"Factors\",\n",
            "            \"start\": 93.92,\n",
            "            \"end\": 94.44\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"contributing\",\n",
            "            \"start\": 94.44,\n",
            "            \"end\": 95.1\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"word\": \"to dementia risk.\",\n",
            "    \"start\": 95.1,\n",
            "    \"end\": 96.48,\n",
            "    \"textcontents\": [\n",
            "        {\n",
            "            \"word\": \"to\",\n",
            "            \"start\": 95.1,\n",
            "            \"end\": 95.46\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"dementia\",\n",
            "            \"start\": 95.46,\n",
            "            \"end\": 95.78\n",
            "        },\n",
            "        {\n",
            "            \"word\": \"risk.\",\n",
            "            \"start\": 95.78,\n",
            "            \"end\": 96.48\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "for line in linelevel_subtitles:\n",
        "  json_str = json.dumps(line, indent=4)\n",
        "  print(json_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XiXr8UWCMxj",
        "outputId": "80ddfa75-e400-49ca-a57c-ad920645310e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting moviepy==2.0.0.dev2\n",
            "  Downloading moviepy-2.0.0.dev2.tar.gz (400 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m286.7/400.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.1/400.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==2.0.0.dev2) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy==2.0.0.dev2) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==2.0.0.dev2) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy==2.0.0.dev2) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy==2.0.0.dev2) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==2.0.0.dev2) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy==2.0.0.dev2) (11.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from proglog<=1.0.0->moviepy==2.0.0.dev2) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==2.0.0.dev2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==2.0.0.dev2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==2.0.0.dev2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==2.0.0.dev2) (2024.12.14)\n",
            "Building wheels for collected packages: moviepy\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-2.0.0.dev2-py3-none-any.whl size=111664 sha256=a225f8c06b2d6922a6243cbcc5e8335aaec5881ed22474029c3c97d82199b2a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/50/ca/52880c49f16c0abe1b5b57b81585f45f061f458b10c377ee1c\n",
            "Successfully built moviepy\n",
            "Installing collected packages: moviepy\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 1.0.3\n",
            "    Uninstalling moviepy-1.0.3:\n",
            "      Successfully uninstalled moviepy-1.0.3\n",
            "Successfully installed moviepy-2.0.0.dev2\n",
            "Collecting imageio==2.25.1\n",
            "  Downloading imageio-2.25.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio==2.25.1) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio==2.25.1) (11.1.0)\n",
            "Downloading imageio-2.25.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.36.1\n",
            "    Uninstalling imageio-2.36.1:\n",
            "      Successfully uninstalled imageio-2.36.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.1 requires imageio!=2.35.0,>=2.33, but you have imageio 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy==2.0.0.dev2\n",
        "!pip install imageio==2.25.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LnuTKjqCO9m",
        "outputId": "5154a4ac-ecd8-4145-897c-d5614fb06ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick-6-common\n",
            "  imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0 libmagickcore-6.q16-6\n",
            "  libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10 libwmflite-0.2-7 netpbm\n",
            "  poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre ghostscript-x imagemagick-doc\n",
            "  autotrace cups-bsd | lpr | lprng enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer\n",
            "  povray radiance sane-utils texlive-base-bin transfig ufraw-batch libfftw3-bin libfftw3-dev\n",
            "  inkscape poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick\n",
            "  imagemagick-6-common imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0\n",
            "  libmagickcore-6.q16-6 libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10\n",
            "  libwmflite-0.2-7 netpbm poppler-data\n",
            "0 upgraded, 26 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 25.1 MB of archives.\n",
            "After this operation, 87.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu8 [770 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6-common all 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [64.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [1,795 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickwand-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [328 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.10 [752 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.10 [5,031 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.10 [49.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.5 [3,120 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6.q16 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [224 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [14.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre-text all 3.5.28-2build2 [50.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre21 amd64 3.5.28-2build2 [624 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr0 amd64 1.2~git20170615.f752187-5 [174 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr-tools amd64 1.2~git20170615.f752187-5 [16.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwmflite-0.2-7 amd64 0.2.12-5ubuntu1 [68.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6-extra amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [70.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnetpbm10 amd64 2:10.0-15.4 [59.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 netpbm amd64 2:10.0-15.4 [1,007 kB]\n",
            "Fetched 25.1 MB in 1s (36.3 MB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 124950 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../01-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../02-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../03-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../04-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickwand-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.10_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../16-imagemagick-6.q16_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../17-imagemagick_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../18-libdjvulibre-text_3.5.28-2build2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../19-libdjvulibre21_3.5.28-2build2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libjxr0:amd64.\n",
            "Preparing to unpack .../20-libjxr0_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libjxr-tools.\n",
            "Preparing to unpack .../21-libjxr-tools_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libwmflite-0.2-7:amd64.\n",
            "Preparing to unpack .../22-libwmflite-0.2-7_0.2.12-5ubuntu1_amd64.deb ...\n",
            "Unpacking libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6-extra:amd64.\n",
            "Preparing to unpack .../23-libmagickcore-6.q16-6-extra_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../24-libnetpbm10_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.4) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../25-netpbm_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.4) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.4) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up netpbm (2:10.0-15.4) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libdjvulibre-text (3.5.28-2build2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install imagemagick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9HA_yQaOCT9O"
      },
      "outputs": [],
      "source": [
        "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GbJiIff6CXPS"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import TextClip, CompositeVideoClip, ColorClip\n",
        "from moviepy.video.fx import fadein, fadeout, scroll\n",
        "\n",
        "def create_caption(textJSON, framesize, font=\"Helvetica-Bold\", fontsize=80, color='white', bgcolor='blue'):\n",
        "    wordcount = len(textJSON['textcontents'])\n",
        "    full_duration = textJSON['end'] - textJSON['start']\n",
        "\n",
        "    word_clips = []\n",
        "    xy_textclips_positions = []\n",
        "\n",
        "    x_pos = 0\n",
        "    y_pos = 0\n",
        "    frame_width = framesize[0]\n",
        "    frame_height = framesize[1]\n",
        "    x_buffer = frame_width * 1 / 10\n",
        "    y_buffer = frame_height * 1 / 5\n",
        "\n",
        "    space_width = \"\"\n",
        "    space_height = \"\"\n",
        "\n",
        "    for index, wordJSON in enumerate(textJSON['textcontents']):\n",
        "        duration = wordJSON['end'] - wordJSON['start']\n",
        "        word_clip = TextClip(wordJSON['word'], font=font, fontsize=fontsize, color=color).set_start(textJSON['start']).set_duration(full_duration)\n",
        "        word_clip_space = TextClip(\" \", font=font, fontsize=fontsize, color=color).set_start(textJSON['start']).set_duration(full_duration)\n",
        "        word_width, word_height = word_clip.size\n",
        "        space_width, space_height = word_clip_space.size\n",
        "\n",
        "        if x_pos + word_width + space_width > frame_width - 2 * x_buffer:\n",
        "            # Move to the next line\n",
        "            x_pos = 0\n",
        "            y_pos = y_pos + word_height + 40\n",
        "\n",
        "            # Store info of each word_clip created\n",
        "            xy_textclips_positions.append({\n",
        "                \"x_pos\": x_pos + x_buffer,\n",
        "                \"y_pos\": y_pos + y_buffer,\n",
        "                \"width\": word_width,\n",
        "                \"height\": word_height,\n",
        "                \"word\": wordJSON['word'],\n",
        "                \"start\": wordJSON['start'],\n",
        "                \"end\": wordJSON['end'],\n",
        "                \"duration\": duration\n",
        "            })\n",
        "\n",
        "            word_clip = word_clip.set_position((x_pos + x_buffer, y_pos + y_buffer))\n",
        "            word_clip_space = word_clip_space.set_position((x_pos + word_width + x_buffer, y_pos + y_buffer))\n",
        "            x_pos = word_width + space_width\n",
        "        else:\n",
        "            # Store info of each word_clip created\n",
        "            xy_textclips_positions.append({\n",
        "                \"x_pos\": x_pos + x_buffer,\n",
        "                \"y_pos\": y_pos + y_buffer,\n",
        "                \"width\": word_width,\n",
        "                \"height\": word_height,\n",
        "                \"word\": wordJSON['word'],\n",
        "                \"start\": wordJSON['start'],\n",
        "                \"end\": wordJSON['end'],\n",
        "                \"duration\": duration\n",
        "            })\n",
        "\n",
        "            word_clip = word_clip.set_position((x_pos + x_buffer, y_pos + y_buffer))\n",
        "            word_clip_space = word_clip_space.set_position((x_pos + word_width + x_buffer, y_pos + y_buffer))\n",
        "\n",
        "            x_pos = x_pos + word_width + space_width\n",
        "\n",
        "        # Apply Fade-in and Fade-out effects to each word clip\n",
        "        word_clip = fadein.fadein(word_clip, 0.5)  # Fade-in effect (0.5 seconds)\n",
        "        word_clip = fadeout.fadeout(word_clip, 0.5)  # Fade-out effect (0.5 seconds)\n",
        "\n",
        "        word_clips.append(word_clip)\n",
        "        word_clips.append(word_clip_space)\n",
        "\n",
        "    # Apply the blue highlight effect for the word being spoken\n",
        "    for highlight_word in xy_textclips_positions:\n",
        "        word_clip_highlight = TextClip(highlight_word['word'], font=font, fontsize=fontsize, color=color, bg_color='blue').set_start(highlight_word['start']).set_duration(highlight_word['duration'])\n",
        "        word_clip_highlight = word_clip_highlight.set_position((highlight_word['x_pos'], highlight_word['y_pos']))\n",
        "\n",
        "        # Apply Fade-in and Fade-out effects for the highlight text\n",
        "        word_clip_highlight = fadein.fadein(word_clip_highlight, 0.5)  # Fade-in effect\n",
        "        word_clip_highlight = fadeout.fadeout(word_clip_highlight, 0.5)  # Fade-out effect\n",
        "\n",
        "        word_clips.append(word_clip_highlight)\n",
        "\n",
        "    return word_clips\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "eLlawSRLCc-8",
        "outputId": "f0c54b05-1023-4127-ccc3-6ea30fb62c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video output.mp4.\n",
            "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import TextClip, CompositeVideoClip, AudioFileClip, ColorClip\n",
        "\n",
        "# Load the audio file correctly using AudioFileClip\n",
        "audio = AudioFileClip(\"./uploads/audio.mp3\")\n",
        "# Get duration in seconds\n",
        "audio_duration = audio.duration\n",
        "frame_size = (1080, 1080)\n",
        "\n",
        "# Generate video clip with text (assuming 'linelevel_subtitles' and 'create_caption' are defined)\n",
        "all_linelevel_splits = []\n",
        "\n",
        "for line in linelevel_subtitles:\n",
        "    out = create_caption(line, frame_size)\n",
        "    all_linelevel_splits.extend(out)\n",
        "\n",
        "# Create a background clip to fit the duration of the audio\n",
        "background_clip = ColorClip(size=frame_size, color=(0, 0, 0)).set_duration(audio_duration)\n",
        "\n",
        "# Combine the text clips with the background\n",
        "final_video = CompositeVideoClip([background_clip] + all_linelevel_splits)\n",
        "\n",
        "# Set the audio of the final video to the loaded audio\n",
        "final_video = final_video.set_audio(audio)  # Pass the AudioFileClip object, not a string path\n",
        "\n",
        "# Save the final clip as a video file with the audio included\n",
        "final_video.write_videofile(\"output.mp4\", fps=24, codec=\"libx264\", audio_codec=\"aac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1VZqDmfL0cj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
