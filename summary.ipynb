{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import PyPDF2\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(api_key=\"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\", model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts full text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=3000):\n",
    "    \"\"\"Splits text into chunks of specified size.\"\"\"\n",
    "    return [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_chunk(chunk):\n",
    "    \"\"\"Uses ChatGroq LLM to summarize a given text chunk.\"\"\"\n",
    "    prompt = f\"Summarize this text in short:\\n\\n{chunk}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if response else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_chunks(chunks):\n",
    "    \"\"\"Summarizes each chunk and returns the combined summary.\"\"\"\n",
    "    summaries = []\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        print(f\"Summarizing chunk {index + 1}/{len(chunks)}...\")\n",
    "        summary = summarize_chunk(chunk)\n",
    "        summaries.append(summary)\n",
    "        time.sleep(15)  # Prevent exceeding API rate limits\n",
    "    return \"\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_resummarization(text):\n",
    "    \"\"\"Creates a final concise summary of all chunk summaries.\"\"\"\n",
    "    prompt = f\"Summarize the following in concise and meaningful words:\\n\\n{text}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if response else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pdf_path):\n",
    "    \"\"\"Main function to process the PDF and generate a summary video script.\"\"\"\n",
    "    print(\"Extracting text from PDF...\")\n",
    "    full_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    print(\"Splitting text into manageable chunks...\")\n",
    "    text_chunks = split_text_into_chunks(full_text)\n",
    "    \n",
    "    print(\"Generating summaries for each chunk...\")\n",
    "    summarized_text = summarize_text_chunks(text_chunks)\n",
    "    \n",
    "    print(\"Generating final summarized text...\")\n",
    "    final_summary = final_resummarization(summarized_text)\n",
    "    \n",
    "    print(\"\\nüìù Final Summary:\\n\", final_summary)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Splitting text into manageable chunks...\n",
      "Generating summaries for each chunk...\n",
      "Summarizing chunk 1/17...\n",
      "Summarizing chunk 2/17...\n",
      "Summarizing chunk 3/17...\n",
      "Summarizing chunk 4/17...\n",
      "Summarizing chunk 5/17...\n",
      "Summarizing chunk 6/17...\n",
      "Summarizing chunk 7/17...\n",
      "Summarizing chunk 8/17...\n",
      "Summarizing chunk 9/17...\n",
      "Summarizing chunk 10/17...\n",
      "Summarizing chunk 11/17...\n",
      "Summarizing chunk 12/17...\n",
      "Summarizing chunk 13/17...\n",
      "Summarizing chunk 14/17...\n",
      "Summarizing chunk 15/17...\n",
      "Summarizing chunk 16/17...\n",
      "Summarizing chunk 17/17...\n",
      "Generating final summarized text...\n",
      "\n",
      "üìù Final Summary:\n",
      " **Federated Learning: A Decentralized Approach to Machine Learning**\n",
      "\n",
      "Federated learning is a technique that enables training of machine learning models on decentralized data from multiple devices, such as smartphones, without compromising user privacy. This approach involves local training on each device and periodic model updates to a central server, reducing the need for direct access to raw data.\n",
      "\n",
      "**Key Benefits:**\n",
      "\n",
      "1. **Improved Privacy**: Federated learning protects sensitive user data by only sharing model updates, rather than raw data.\n",
      "2. **Reduced Communication Costs**: By computing updates locally and sharing only the updates, communication costs are significantly reduced.\n",
      "3. **Increased Efficiency**: Federated learning can lead to faster training times and improved model performance.\n",
      "\n",
      "**Algorithms and Techniques:**\n",
      "\n",
      "1. **FedAvg**: A federated averaging algorithm that combines models from multiple clients to achieve better performance.\n",
      "2. **FedSGD**: A federated stochastic gradient descent algorithm that updates models using a weighted average of client updates.\n",
      "\n",
      "**Experimental Results:**\n",
      "\n",
      "1. **FedAvg outperforms FedSGD**: In many cases, FedAvg achieves higher accuracy and faster convergence than FedSGD.\n",
      "2. **Non-IID data settings**: FedAvg is robust to non-identically distributed data and unbalanced client datasets.\n",
      "3. **Hyperparameter tuning**: Experimenting with different client fractions, batch sizes, and local epochs can significantly impact performance.\n",
      "\n",
      "**Future Directions:**\n",
      "\n",
      "1. **Stronger privacy guarantees**: Developing techniques to provide stronger privacy guarantees for federated learning.\n",
      "2. **Scalability and efficiency**: Improving the scalability and efficiency of federated learning algorithms for large-scale applications.\n"
     ]
    }
   ],
   "source": [
    "pdf_file_path = \"sample_paper.pdf\"  # Replace with your actual PDF file path\n",
    "final_output = main(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_speech_for_video(text):\n",
    "    \"\"\"Generates a direct, engaging speech based on the provided text, suitable for a 1 to 1.5-minute video.\"\"\"\n",
    "    prompt = f\"Create a direct and engaging speech based on the following text. The speech should be concise, conversational, and impactful, without any additional structure for timing or visuals. Make sure it flows naturally and emphasizes the key points in a clear and compelling way. The speech should be suitable for a 1 to 1.5-minute video:\\n\\n{text}\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if response else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = final_speech_for_video(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a world where AI models can be trained on data from millions of devices without compromising user privacy. That's the power of Federated Learning. This game-changing approach allows us to train models locally on each device and share only the updates, protecting sensitive user data and reducing communication costs.\n",
      "\n",
      "Not only does Federated Learning prioritize user privacy, but it also leads to faster training times and improved model performance. It's a win-win-win for users, developers, and the environment. Our algorithms, like FedAvg and FedSGD, combine models from multiple clients to achieve better performance, with impressive results. FedAvg has outperformed FedSGD in many cases, achieving higher accuracy and faster convergence.\n",
      "\n",
      "As we move forward, we're working to develop stronger privacy guarantees and improve scalability and efficiency for large-scale applications. The potential of Federated Learning is vast, with the power to transform industries like healthcare, finance, and education. This decentralized, private, and efficient approach to machine learning has the potential to revolutionize the way we live and work. Let's harness its potential and create a future where AI benefits everyone while protecting individual privacy and security.\n"
     ]
    }
   ],
   "source": [
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ppt_content(text, llm):\n",
    "    \"\"\"\n",
    "    Creates PowerPoint slide content from the provided text and returns it in JSON format.\n",
    "    The content is divided into slide-sized chunks, each slide having a title and content.(around 7 to 8 slides)\n",
    "\n",
    "    Args:\n",
    "    - text (str): The long text to be summarized and divided into slides.\n",
    "    - llm (object): An LLM instance to summarize content (could be OpenAI or any other model).\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of dictionaries representing slides (title and content).\n",
    "    \"\"\"\n",
    "    # Function to split the text into sections for slides (optional, could be based on your specific text structure)\n",
    "    def split_text_into_sections(text):\n",
    "        # Example approach: split text into paragraphs based on sentence/sections structure\n",
    "        # You can define more complex logic if needed\n",
    "        sections = text.split(\"\\n\\n\")  # Split based on double line breaks for sections (adjust as per your need)\n",
    "        return sections\n",
    "\n",
    "    # Process each section to create slide content\n",
    "    slides = []\n",
    "    sections = split_text_into_sections(text)\n",
    "    \n",
    "    for idx, section in enumerate(sections):\n",
    "        title = f\"Slide {idx + 1}\"  # You can adjust the title generation logic if needed\n",
    "        # Summarize the section (you can change this prompt based on the desired output style)\n",
    "        prompt = f\"Summarize the following in a concise and clear manner:\\n\\n{section}\"\n",
    "        response = llm.invoke(prompt)\n",
    "        content = response.content if response else \"No summary available\"\n",
    "\n",
    "        # Append the slide content as a dictionary\n",
    "        slides.append({\n",
    "            \"title\": title,\n",
    "            \"content\": content\n",
    "        })\n",
    "    \n",
    "    return slides\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming `llm` is an initialized language model (like OpenAI's GPT)\n",
    "# ppt_content = generate_ppt_content(long_text, llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_content = generate_ppt_content(final_output, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Slide 1',\n",
       "  'content': 'Federated Learning is a technique that trains AI models on data from multiple devices without exposing user data. It works by training models locally on each device and sharing only the updates, ensuring user privacy and reducing communication costs.'},\n",
       " {'title': 'Slide 2',\n",
       "  'content': 'Federated Learning offers three key benefits: \\n\\n1. Prioritizing user privacy\\n2. Faster training times\\n3. Improved model performance\\n\\nIts algorithms, such as FedAvg and FedSGD, combine models from multiple clients to achieve better results, with FedAvg often outperforming FedSGD in terms of accuracy and convergence speed.'},\n",
       " {'title': 'Slide 3',\n",
       "  'content': 'Federated Learning is being developed to improve privacy, scalability, and efficiency, with the potential to transform industries like healthcare, finance, and education, and create a future where AI benefits everyone while protecting individual privacy and security.'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "client = ElevenLabs(\n",
    "  api_key='sk_b762c6b6416e5937608aea3ecf771bedade32a75eb82a4ce',\n",
    ")\n",
    "wJotvZOSSl08PFYC81Xe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: {\"detail\":{\"status\":\"detected_unusual_activity\",\"message\":\"Unusual activity detected. Free Tier usage disabled. If you are using a proxy/VPN you might need to purchase a Paid Plan to not trigger our abuse detectors. Free Tier only works if users do not abuse it, for example by creating multiple free accounts. If we notice that many people try to abuse it, we will need to reconsider Free Tier altogether. \\nPlease play fair and purchase any Paid Subscription to continue.\"}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your ElevenLabs API key\n",
    "API_KEY = \"sk_b762c6b6416e5937608aea3ecf771bedade32a75eb82a4ce\"\n",
    "\n",
    "\n",
    "# Function to auto-format text into SSML\n",
    "def format_text_to_ssml(text):\n",
    "    sentences = text.split(\". \")\n",
    "    formatted_text = \"\"\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if sentence.strip():\n",
    "            emphasis_level = \"moderate\" if i % 2 == 0 else \"strong\"\n",
    "            pause_time = \"500ms\" if i % 2 == 0 else \"700ms\"\n",
    "            formatted_text += f'<p> <prosody pitch=\"+5%\" rate=\"95%\"><emphasis level=\"{emphasis_level}\">{sentence.strip()}.</emphasis></prosody> </p>\\n'\n",
    "            formatted_text += f'<break time=\"{pause_time}\"/>\\n'\n",
    "\n",
    "    ssml_output = f\"<speak>\\n{formatted_text}</speak>\"\n",
    "    return ssml_output\n",
    "\n",
    "# Function to generate speech from text using ElevenLabs API\n",
    "def generate_speech(text, voice_id):\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream\"\n",
    "\n",
    "    ssml_text = format_text_to_ssml(text)\n",
    "\n",
    "    headers = {\n",
    "        \"xi-api-key\": API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"text\": ssml_text,\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,  # Adjust for naturalness\n",
    "            \"similarity_boost\": 0.8\n",
    "        },\n",
    "        \"model_id\": \"eleven_multilingual_v2\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(\"audio.mp3\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"‚úÖ Audio saved as audio.mp3\")\n",
    "    else:\n",
    "        print(\"‚ùå Error:\", response.text)\n",
    "\n",
    "# Execution starts here\n",
    "if __name__ == \"__main__\":\n",
    "    user_text = \"\"\"Imagine a world where AI models can be trained on data from millions of devices without compromising user privacy. \n",
    "    That's the power of Federated Learning. This game-changing approach allows us to train models locally on each device and share only the updates, \n",
    "    protecting sensitive user data and reducing communication costs.\n",
    "\n",
    "    Not only does Federated Learning prioritize user privacy, but it also leads to faster training times and improved model performance. \n",
    "    It's a win-win-win for users, developers, and the environment. Our algorithms, like FedAvg and FedSGD, combine models from multiple clients \n",
    "    to achieve better performance, with impressive results. FedAvg has outperformed FedSGD in many cases, achieving higher accuracy and faster convergence.\n",
    "\n",
    "    As we move forward, we're working to develop stronger privacy guarantees and improve scalability and efficiency for large-scale applications. \n",
    "    The potential of Federated Learning is vast, with the power to transform industries like healthcare, finance, and education. \n",
    "    This decentralized, private, and efficient approach to machine learning has the potential to revolutionize the way we live and work. \n",
    "    Let's harness its potential and create a future where AI benefits everyone while protecting individual privacy and security.\"\"\"\n",
    "\n",
    "    best_voice = \"ErXwobaYiN019PkySvjV\"  # Fetch best voice dynamically\n",
    "    if best_voice:\n",
    "        generate_speech(user_text, best_voice)\n",
    "    else:\n",
    "        print(\"‚ùå No suitable voice found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiError",
     "evalue": "status_code: 401, body: {'detail': {'status': 'detected_unusual_activity', 'message': 'Unusual activity detected. Free Tier usage disabled. If you are using a proxy/VPN you might need to purchase a Paid Plan to not trigger our abuse detectors. Free Tier only works if users do not abuse it, for example by creating multiple free accounts. If we notice that many people try to abuse it, we will need to reconsider Free Tier altogether. \\nPlease play fair and purchase any Paid Subscription to continue.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Save the streamed audio as an MP3 file\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maudio_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jaimin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\elevenlabs\\text_to_speech\\client.py:529\u001b[0m, in \u001b[0;36mTextToSpeechClient.convert_as_stream\u001b[1;34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, language_code, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, use_pvc_as_ivc, apply_text_normalization, request_options)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m--> 529\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[1;31mApiError\u001b[0m: status_code: 401, body: {'detail': {'status': 'detected_unusual_activity', 'message': 'Unusual activity detected. Free Tier usage disabled. If you are using a proxy/VPN you might need to purchase a Paid Plan to not trigger our abuse detectors. Free Tier only works if users do not abuse it, for example by creating multiple free accounts. If we notice that many people try to abuse it, we will need to reconsider Free Tier altogether. \\nPlease play fair and purchase any Paid Subscription to continue.'}}"
     ]
    }
   ],
   "source": [
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "client = ElevenLabs(api_key=\"sk_ebb682d654e1b5485528af9a0418c0b432bf86793809336e\")\n",
    "user_text = \"\"\"Imagine a world where AI models can be trained on data from millions of devices without compromising user privacy. \n",
    "    That's the power of Federated Learning. This game-changing approach allows us to train models locally on each device and share only the updates, \n",
    "    protecting sensitive user data and reducing communication costs.\n",
    "\n",
    "    Not only does Federated Learning prioritize user privacy, but it also leads to faster training times and improved model performance. \n",
    "    It's a win-win-win for users, developers, and the environment. Our algorithms, like FedAvg and FedSGD, combine models from multiple clients \n",
    "    to achieve better performance, with impressive results. FedAvg has outperformed FedSGD in many cases, achieving higher accuracy and faster convergence.\n",
    "\n",
    "    As we move forward, we're working to develop stronger privacy guarantees and improve scalability and efficiency for large-scale applications. \n",
    "    The potential of Federated Learning is vast, with the power to transform industries like healthcare, finance, and education. \n",
    "    This decentralized, private, and efficient approach to machine learning has the potential to revolutionize the way we live and work. \n",
    "    Let's harness its potential and create a future where AI benefits everyone while protecting individual privacy and security.\"\"\"\n",
    "\n",
    "audio_stream = client.text_to_speech.convert_as_stream(\n",
    "    text=user_text,\n",
    "    voice_id=\"ErXwobaYiN019PkySvjV\",\n",
    "    model_id=\"eleven_multilingual_v2\"\n",
    ")\n",
    "\n",
    "# Save the streamed audio as an MP3 file\n",
    "with open(\"output.mp3\", \"wb\") as f:\n",
    "    for chunk in audio_stream:\n",
    "        if isinstance(chunk, bytes):\n",
    "            f.write(chunk)\n",
    "\n",
    "print(\"Audio saved as output.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
